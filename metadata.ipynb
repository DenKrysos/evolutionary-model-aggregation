{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed8c94-fe42-46ba-915a-de9a5768358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.94 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "# loading iris dataset \n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "# Voting Classifier with hard voting \n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "# Ensemble of Models \n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "#estimator = [] \n",
    "#estimator.append(('LR',LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200))) \n",
    "#estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
    "# estimator.append(('DTC', DecisionTreeClassifier())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd241f32-f1d7-47c6-8be3-ad66dddb83df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3128285/2738165774.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# calling the model and compile it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mseq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     seq_model.compile(\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "# More Model ensembling techniques now #\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Loading some example data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 2])\n",
    "\n",
    "clf1 = clf1.fit(X, y)\n",
    "clf2 = clf2.fit(X, y)\n",
    "clf3 = clf3.fit(X, y)\n",
    "eclf = eclf.fit(X, y)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Deicision Tree', 'K-Nearest Neighbour', 'SVC', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7269cc0d-a529-4233-8375-0c32fe023f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "(100, 2)\n",
      "(100,)\n",
      "Test Set\n",
      "(50, 2)\n",
      "(50,)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3128285/4189055219.py\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     model.fit(X[train], y[train],\n\u001b[0m\u001b[1;32m     63\u001b[0m               batch_size=128, epochs=2, validation_data=(X[test], y[test]))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Now we want to analyse the models using tfma \n",
    "# This setup was tested with TF 2.10 and TFMA 0.41 (using colab), but it should\n",
    "# also work with the latest release.\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Confirm that we're using Python 3\n",
    "assert sys.version_info.major==3, 'This notebook must be run using Python 3.'\n",
    "\n",
    "import tensorflow as tf\n",
    "# print('TF version: {}'.format(tf.__version__))\n",
    "import apache_beam as beam\n",
    "#print('Beam version: {}'.format(beam.__version__))\n",
    "import tensorflow_model_analysis as tfma\n",
    "# print('TFMA version: {}'.format(tfma.__version__))\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(2,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "for kfold, (train, test) in enumerate(KFold(n_splits=3, \n",
    "                                shuffle=True).split(X, y)):\n",
    "    # clear the session \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # calling the model and compile it \n",
    "    #seq_model = my_model()\n",
    "    model.compile(\n",
    "        loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics  = tf.keras.metrics.CategoricalAccuracy(),\n",
    "        optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "    print('Train Set')\n",
    "    print(X[train].shape)\n",
    "    print(y[train].shape)\n",
    "\n",
    "    print('Test Set')\n",
    "    print(X[test].shape)\n",
    "    print(y[test].shape)\n",
    "\n",
    "    # run the model \n",
    "    model.fit(X[train], y[train],\n",
    "              batch_size=128, epochs=2, validation_data=(X[test], y[test]))\n",
    "    \n",
    "    model.save_weights(f'wg_{kfold}.h5')\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# The tf.keras.callbacks.ModelCheckpoint callback allows you to continually \n",
    "# save the model both during and at the end of training\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(X[train], \n",
    "          y[train],  \n",
    "          epochs=10,\n",
    "          validation_data=(X[test], y[test]),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "filepath = \"/home/antillas/collabos/model_aggregation\"\n",
    "\n",
    "# Save all The model's configuration (architecture), The model's weights, \n",
    "# Saves a model as a .keras file - The model's optimizer's state (if any)\n",
    "\n",
    "model.save(\"kera_model_one.keras\")\n",
    "\n",
    "# Saves all layer weights to a .weights.h5 file.\n",
    "model.save_weights(\n",
    "    filepath, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa96d0a-273f-4f54-9da7-5159329a55cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1006610/4155883061.py\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_federated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# the directory structure. The python import statements above implicitly add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# these to locals().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpython\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mproto\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "# Next steps for the \n",
    "'''\n",
    "1: Use the metadat extractor here to retrieve any metadata about the pretrained models\n",
    "\n",
    "2: A component for the metadata schema validator\n",
    "\n",
    "3: Give weights to each model metadata -> Kind of a fitnesss functions\n",
    "\n",
    "4: Encode metadata as chromosomes\n",
    "\n",
    "5: Do generic algorithm for Model aggregation\n",
    "\n",
    "6: Do FedAvg aggregations, Bagging/stacking/Voting\n",
    "\n",
    "7: Compare results from 5 to results from 6\n",
    "'''\n",
    "\n",
    "'''\n",
    "  FedAvg - Load pretrained models and do aggregations - mobilenet models\n",
    "'''\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "!pip install tf-keras==2.15.0\n",
    "!pip install tensorflow==2.15.2\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  # Get pre-trained mobileNet models \n",
    "  keras_model = timm.create_model('mobilenetv4_hybrid_large.ix_e600_r384_in1k', pretrained=True, features_only=True,)\n",
    "    \n",
    "  # keras_model = create_keras_model()\n",
    "  return tff.learning.models.from_keras_model(\n",
    "      keras_model,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "if \"__name__\" == main:\n",
    "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "        model_fn,\n",
    "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "\n",
    "    print(training_process.initialize.type_signature.formatted_representation())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53e7f6bc-e6da-4677-aa99-26d7d37be063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----->  (48842, 15)\n",
      "{\n",
      "  \"version\": \"0.4.37\",\n",
      "  \"metrics\": [\n",
      "    {\n",
      "      \"metric\": \"DataDriftTable\",\n",
      "      \"result\": {\n",
      "        \"number_of_columns\": 15,\n",
      "        \"number_of_drifted_columns\": 3,\n",
      "        \"share_of_drifted_columns\": 0.2,\n",
      "        \"dataset_drift\": false,\n",
      "        \"drift_by_columns\": {\n",
      "          \"age\": {\n",
      "            \"column_name\": \"age\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.02723374709437682,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  17.0,\n",
      "                  24.3,\n",
      "                  31.6,\n",
      "                  38.9,\n",
      "                  46.2,\n",
      "                  53.5,\n",
      "                  60.8,\n",
      "                  68.1,\n",
      "                  75.4,\n",
      "                  82.7,\n",
      "                  90.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.02471021672878118,\n",
      "                  0.025839691234843417,\n",
      "                  0.0262859521410848,\n",
      "                  0.025211766596857754,\n",
      "                  0.015942967066340047,\n",
      "                  0.010173168977679455,\n",
      "                  0.0061528716099474344,\n",
      "                  0.0018640278561586543,\n",
      "                  0.000568686464590777,\n",
      "                  0.0002369526935794904\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  17.0,\n",
      "                  24.3,\n",
      "                  31.6,\n",
      "                  38.9,\n",
      "                  46.2,\n",
      "                  53.5,\n",
      "                  60.8,\n",
      "                  68.1,\n",
      "                  75.4,\n",
      "                  82.7,\n",
      "                  90.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.02104876054252575,\n",
      "                  0.020739077628796638,\n",
      "                  0.02384558435714183,\n",
      "                  0.026835959992838568,\n",
      "                  0.018658395552179158,\n",
      "                  0.012580868370245284,\n",
      "                  0.00869047676652328,\n",
      "                  0.0029516652714806184,\n",
      "                  0.001287119610186633,\n",
      "                  0.000348393277945254\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"capital-gain\": {\n",
      "            \"column_name\": \"capital-gain\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.02138191945976756,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  9999.9,\n",
      "                  19999.8,\n",
      "                  29999.699999999997,\n",
      "                  39999.6,\n",
      "                  49999.5,\n",
      "                  59999.399999999994,\n",
      "                  69999.3,\n",
      "                  79999.2,\n",
      "                  89999.09999999999,\n",
      "                  99999.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  9.822510079686088e-05,\n",
      "                  1.2569676248842519e-06,\n",
      "                  1.7297719608498882e-07,\n",
      "                  1.1531813072332584e-08,\n",
      "                  2.882953268083146e-09,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  3.3153962582956155e-07\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  9999.9,\n",
      "                  19999.8,\n",
      "                  29999.699999999997,\n",
      "                  39999.6,\n",
      "                  49999.5,\n",
      "                  59999.399999999994,\n",
      "                  69999.3,\n",
      "                  79999.2,\n",
      "                  89999.09999999999,\n",
      "                  99999.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  9.634147913361861e-05,\n",
      "                  2.2395137409516095e-06,\n",
      "                  4.804004239265283e-07,\n",
      "                  1.4129424233133181e-08,\n",
      "                  1.4129424233133181e-08,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  9.113478630370894e-07\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"capital-loss\": {\n",
      "            \"column_name\": \"capital-loss\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.0027433051180048777,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  435.6,\n",
      "                  871.2,\n",
      "                  1306.8000000000002,\n",
      "                  1742.4,\n",
      "                  2178.0,\n",
      "                  2613.6000000000004,\n",
      "                  3049.2000000000003,\n",
      "                  3484.8,\n",
      "                  3920.4,\n",
      "                  4356.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.0021929683487458603,\n",
      "                  1.1912910903101098e-06,\n",
      "                  1.257473928660671e-06,\n",
      "                  3.4745990134044877e-05,\n",
      "                  5.201971094354147e-05,\n",
      "                  1.2310007933204457e-05,\n",
      "                  5.95645545155055e-07,\n",
      "                  6.618283835056166e-08,\n",
      "                  3.309141917528083e-07,\n",
      "                  1.98548515051685e-07\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  390.0,\n",
      "                  780.0,\n",
      "                  1170.0,\n",
      "                  1560.0,\n",
      "                  1950.0,\n",
      "                  2340.0,\n",
      "                  2730.0,\n",
      "                  3120.0,\n",
      "                  3510.0,\n",
      "                  3900.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.002434221847856606,\n",
      "                  1.0868679183762194e-06,\n",
      "                  1.2680125714389225e-06,\n",
      "                  7.970364734758943e-06,\n",
      "                  6.23137606535699e-05,\n",
      "                  3.967067902073201e-05,\n",
      "                  1.4672716898078962e-05,\n",
      "                  2.173735836752439e-06,\n",
      "                  1.811446530627032e-07,\n",
      "                  5.434339591881097e-07\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"education-num\": {\n",
      "            \"column_name\": \"education-num\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 6.873706387420469,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  9.0,\n",
      "                  9.4,\n",
      "                  9.8,\n",
      "                  10.2,\n",
      "                  10.6,\n",
      "                  11.0,\n",
      "                  11.4,\n",
      "                  11.8,\n",
      "                  12.2,\n",
      "                  12.6,\n",
      "                  13.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1.138984917551319,\n",
      "                  0.0,\n",
      "                  0.7847156361856423,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.5762994462630397\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  2.5,\n",
      "                  4.0,\n",
      "                  5.5,\n",
      "                  7.0,\n",
      "                  8.5,\n",
      "                  10.0,\n",
      "                  11.5,\n",
      "                  13.0,\n",
      "                  14.5,\n",
      "                  16.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.015542211232779936,\n",
      "                  0.023972683386318142,\n",
      "                  0.08058401036147415,\n",
      "                  0.06541858000706464,\n",
      "                  0.11628399858707171,\n",
      "                  0.0,\n",
      "                  0.09706817379018015,\n",
      "                  0.07540327328388084,\n",
      "                  0.12513834922877665,\n",
      "                  0.06725538678912045\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"fnlwgt\": {\n",
      "            \"column_name\": \"fnlwgt\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.001663513925995391,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  12285.0,\n",
      "                  160096.5,\n",
      "                  307908.0,\n",
      "                  455719.5,\n",
      "                  603531.0,\n",
      "                  751342.5,\n",
      "                  899154.0,\n",
      "                  1046965.5,\n",
      "                  1194777.0,\n",
      "                  1342588.5,\n",
      "                  1490400.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  2.7682113067215177e-06,\n",
      "                  3.1635586130503076e-06,\n",
      "                  7.115081270288237e-07,\n",
      "                  9.166908434856009e-08,\n",
      "                  2.184454775965687e-08,\n",
      "                  4.2908933099325996e-09,\n",
      "                  2.340487259963236e-09,\n",
      "                  1.170243629981618e-09,\n",
      "                  3.900812099938727e-10,\n",
      "                  3.900812099938727e-10\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  13769.0,\n",
      "                  157935.6,\n",
      "                  302102.2,\n",
      "                  446268.80000000005,\n",
      "                  590435.4,\n",
      "                  734602.0,\n",
      "                  878768.6000000001,\n",
      "                  1022935.2000000001,\n",
      "                  1167101.8,\n",
      "                  1311268.4000000001,\n",
      "                  1455435.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  2.7559464969112866e-06,\n",
      "                  3.229318530342351e-06,\n",
      "                  8.061045496833332e-07,\n",
      "                  1.1172756068559274e-07,\n",
      "                  2.1561459079675788e-08,\n",
      "                  8.330563735329276e-09,\n",
      "                  9.80066321803445e-10,\n",
      "                  9.80066321803445e-10,\n",
      "                  4.900331609017221e-10,\n",
      "                  9.80066321803446e-10\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"hours-per-week\": {\n",
      "            \"column_name\": \"hours-per-week\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.008522799705411234,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  10.8,\n",
      "                  20.6,\n",
      "                  30.400000000000002,\n",
      "                  40.2,\n",
      "                  50.0,\n",
      "                  59.800000000000004,\n",
      "                  69.60000000000001,\n",
      "                  79.4,\n",
      "                  89.2,\n",
      "                  99.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.0020562899821905873,\n",
      "                  0.006445395351902112,\n",
      "                  0.007127883586334467,\n",
      "                  0.0567789026412883,\n",
      "                  0.009940205793736761,\n",
      "                  0.012011204574083209,\n",
      "                  0.005336351970949533,\n",
      "                  0.0013620347092335367,\n",
      "                  0.0006089442436530068,\n",
      "                  0.0003736034731590911\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  10.8,\n",
      "                  20.6,\n",
      "                  30.400000000000002,\n",
      "                  40.2,\n",
      "                  50.0,\n",
      "                  59.800000000000004,\n",
      "                  69.60000000000001,\n",
      "                  79.4,\n",
      "                  89.2,\n",
      "                  99.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.003070956393860971,\n",
      "                  0.008196425868121887,\n",
      "                  0.007028597380315601,\n",
      "                  0.05289830520692911,\n",
      "                  0.009313792631146421,\n",
      "                  0.012579387106308432,\n",
      "                  0.005968901159898786,\n",
      "                  0.001585939921712239,\n",
      "                  0.0007785523252041899,\n",
      "                  0.0006199583330329661\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"class\": {\n",
      "            \"column_name\": \"class\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.009418183755514647,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"<=50K\",\n",
      "                  \">50K\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  26808,\n",
      "                  7879\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"<=50K\",\n",
      "                  \">50K\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  10347,\n",
      "                  3808\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"education\": {\n",
      "            \"column_name\": \"education\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 15.016729259060078,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"10th\",\n",
      "                  \"11th\",\n",
      "                  \"12th\",\n",
      "                  \"1st-4th\",\n",
      "                  \"5th-6th\",\n",
      "                  \"7th-8th\",\n",
      "                  \"9th\",\n",
      "                  \"Assoc-acdm\",\n",
      "                  \"Assoc-voc\",\n",
      "                  \"Bachelors\",\n",
      "                  \"Doctorate\",\n",
      "                  \"HS-grad\",\n",
      "                  \"Masters\",\n",
      "                  \"Preschool\",\n",
      "                  \"Prof-school\",\n",
      "                  \"Some-college\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  7535,\n",
      "                  0,\n",
      "                  14892,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  10260\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"10th\",\n",
      "                  \"11th\",\n",
      "                  \"12th\",\n",
      "                  \"1st-4th\",\n",
      "                  \"5th-6th\",\n",
      "                  \"7th-8th\",\n",
      "                  \"9th\",\n",
      "                  \"Assoc-acdm\",\n",
      "                  \"Assoc-voc\",\n",
      "                  \"Bachelors\",\n",
      "                  \"Doctorate\",\n",
      "                  \"HS-grad\",\n",
      "                  \"Masters\",\n",
      "                  \"Preschool\",\n",
      "                  \"Prof-school\",\n",
      "                  \"Some-college\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1389,\n",
      "                  1812,\n",
      "                  657,\n",
      "                  247,\n",
      "                  509,\n",
      "                  955,\n",
      "                  756,\n",
      "                  1601,\n",
      "                  2061,\n",
      "                  0,\n",
      "                  594,\n",
      "                  0,\n",
      "                  2657,\n",
      "                  83,\n",
      "                  834,\n",
      "                  0\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"marital-status\": {\n",
      "            \"column_name\": \"marital-status\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.010266569095702678,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Divorced\",\n",
      "                  \"Married-AF-spouse\",\n",
      "                  \"Married-civ-spouse\",\n",
      "                  \"Married-spouse-absent\",\n",
      "                  \"Never-married\",\n",
      "                  \"Separated\",\n",
      "                  \"Widowed\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4819,\n",
      "                  30,\n",
      "                  15558,\n",
      "                  406,\n",
      "                  11805,\n",
      "                  1060,\n",
      "                  1009\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Divorced\",\n",
      "                  \"Married-AF-spouse\",\n",
      "                  \"Married-civ-spouse\",\n",
      "                  \"Married-spouse-absent\",\n",
      "                  \"Never-married\",\n",
      "                  \"Separated\",\n",
      "                  \"Widowed\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1814,\n",
      "                  7,\n",
      "                  6821,\n",
      "                  222,\n",
      "                  4312,\n",
      "                  470,\n",
      "                  509\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"native-country\": {\n",
      "            \"column_name\": \"native-country\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.09983207386210956,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Cambodia\",\n",
      "                  \"Canada\",\n",
      "                  \"China\",\n",
      "                  \"Columbia\",\n",
      "                  \"Cuba\",\n",
      "                  \"Dominican-Republic\",\n",
      "                  \"Ecuador\",\n",
      "                  \"El-Salvador\",\n",
      "                  \"England\",\n",
      "                  \"France\",\n",
      "                  \"Germany\",\n",
      "                  \"Greece\",\n",
      "                  \"Guatemala\",\n",
      "                  \"Haiti\",\n",
      "                  \"Holand-Netherlands\",\n",
      "                  \"Honduras\",\n",
      "                  \"Hong\",\n",
      "                  \"Hungary\",\n",
      "                  \"India\",\n",
      "                  \"Iran\",\n",
      "                  \"Ireland\",\n",
      "                  \"Italy\",\n",
      "                  \"Jamaica\",\n",
      "                  \"Japan\",\n",
      "                  \"Laos\",\n",
      "                  \"Mexico\",\n",
      "                  \"Nicaragua\",\n",
      "                  \"Outlying-US(Guam-USVI-etc)\",\n",
      "                  \"Peru\",\n",
      "                  \"Philippines\",\n",
      "                  \"Poland\",\n",
      "                  \"Portugal\",\n",
      "                  \"Puerto-Rico\",\n",
      "                  \"Scotland\",\n",
      "                  \"South\",\n",
      "                  \"Taiwan\",\n",
      "                  \"Thailand\",\n",
      "                  \"Trinadad&Tobago\",\n",
      "                  \"United-States\",\n",
      "                  \"Vietnam\",\n",
      "                  \"Yugoslavia\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  22,\n",
      "                  123,\n",
      "                  66,\n",
      "                  51,\n",
      "                  74,\n",
      "                  45,\n",
      "                  30,\n",
      "                  60,\n",
      "                  86,\n",
      "                  22,\n",
      "                  147,\n",
      "                  30,\n",
      "                  29,\n",
      "                  46,\n",
      "                  1,\n",
      "                  12,\n",
      "                  14,\n",
      "                  13,\n",
      "                  63,\n",
      "                  37,\n",
      "                  28,\n",
      "                  56,\n",
      "                  75,\n",
      "                  68,\n",
      "                  13,\n",
      "                  312,\n",
      "                  31,\n",
      "                  18,\n",
      "                  34,\n",
      "                  216,\n",
      "                  57,\n",
      "                  27,\n",
      "                  116,\n",
      "                  16,\n",
      "                  91,\n",
      "                  33,\n",
      "                  19,\n",
      "                  16,\n",
      "                  31848,\n",
      "                  63,\n",
      "                  16\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Cambodia\",\n",
      "                  \"Canada\",\n",
      "                  \"China\",\n",
      "                  \"Columbia\",\n",
      "                  \"Cuba\",\n",
      "                  \"Dominican-Republic\",\n",
      "                  \"Ecuador\",\n",
      "                  \"El-Salvador\",\n",
      "                  \"England\",\n",
      "                  \"France\",\n",
      "                  \"Germany\",\n",
      "                  \"Greece\",\n",
      "                  \"Guatemala\",\n",
      "                  \"Haiti\",\n",
      "                  \"Holand-Netherlands\",\n",
      "                  \"Honduras\",\n",
      "                  \"Hong\",\n",
      "                  \"Hungary\",\n",
      "                  \"India\",\n",
      "                  \"Iran\",\n",
      "                  \"Ireland\",\n",
      "                  \"Italy\",\n",
      "                  \"Jamaica\",\n",
      "                  \"Japan\",\n",
      "                  \"Laos\",\n",
      "                  \"Mexico\",\n",
      "                  \"Nicaragua\",\n",
      "                  \"Outlying-US(Guam-USVI-etc)\",\n",
      "                  \"Peru\",\n",
      "                  \"Philippines\",\n",
      "                  \"Poland\",\n",
      "                  \"Portugal\",\n",
      "                  \"Puerto-Rico\",\n",
      "                  \"Scotland\",\n",
      "                  \"South\",\n",
      "                  \"Taiwan\",\n",
      "                  \"Thailand\",\n",
      "                  \"Trinadad&Tobago\",\n",
      "                  \"United-States\",\n",
      "                  \"Vietnam\",\n",
      "                  \"Yugoslavia\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  6,\n",
      "                  59,\n",
      "                  56,\n",
      "                  34,\n",
      "                  64,\n",
      "                  58,\n",
      "                  15,\n",
      "                  95,\n",
      "                  41,\n",
      "                  16,\n",
      "                  59,\n",
      "                  19,\n",
      "                  59,\n",
      "                  29,\n",
      "                  0,\n",
      "                  8,\n",
      "                  16,\n",
      "                  6,\n",
      "                  88,\n",
      "                  22,\n",
      "                  9,\n",
      "                  49,\n",
      "                  31,\n",
      "                  24,\n",
      "                  10,\n",
      "                  639,\n",
      "                  18,\n",
      "                  5,\n",
      "                  12,\n",
      "                  79,\n",
      "                  30,\n",
      "                  40,\n",
      "                  68,\n",
      "                  5,\n",
      "                  24,\n",
      "                  32,\n",
      "                  11,\n",
      "                  11,\n",
      "                  11984,\n",
      "                  23,\n",
      "                  7\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"occupation\": {\n",
      "            \"column_name\": \"occupation\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.19182922339975303,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Adm-clerical\",\n",
      "                  \"Armed-Forces\",\n",
      "                  \"Craft-repair\",\n",
      "                  \"Exec-managerial\",\n",
      "                  \"Farming-fishing\",\n",
      "                  \"Handlers-cleaners\",\n",
      "                  \"Machine-op-inspct\",\n",
      "                  \"Other-service\",\n",
      "                  \"Priv-house-serv\",\n",
      "                  \"Prof-specialty\",\n",
      "                  \"Protective-serv\",\n",
      "                  \"Sales\",\n",
      "                  \"Tech-support\",\n",
      "                  \"Transport-moving\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4670,\n",
      "                  10,\n",
      "                  4501,\n",
      "                  4505,\n",
      "                  939,\n",
      "                  1422,\n",
      "                  2122,\n",
      "                  3366,\n",
      "                  129,\n",
      "                  3216,\n",
      "                  781,\n",
      "                  4351,\n",
      "                  1042,\n",
      "                  1726\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Adm-clerical\",\n",
      "                  \"Armed-Forces\",\n",
      "                  \"Craft-repair\",\n",
      "                  \"Exec-managerial\",\n",
      "                  \"Farming-fishing\",\n",
      "                  \"Handlers-cleaners\",\n",
      "                  \"Machine-op-inspct\",\n",
      "                  \"Other-service\",\n",
      "                  \"Priv-house-serv\",\n",
      "                  \"Prof-specialty\",\n",
      "                  \"Protective-serv\",\n",
      "                  \"Sales\",\n",
      "                  \"Tech-support\",\n",
      "                  \"Transport-moving\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  941,\n",
      "                  5,\n",
      "                  1611,\n",
      "                  1581,\n",
      "                  551,\n",
      "                  650,\n",
      "                  900,\n",
      "                  1557,\n",
      "                  113,\n",
      "                  2956,\n",
      "                  202,\n",
      "                  1153,\n",
      "                  404,\n",
      "                  629\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"race\": {\n",
      "            \"column_name\": \"race\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.003051106861330099,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Amer-Indian-Eskimo\",\n",
      "                  \"Asian-Pac-Islander\",\n",
      "                  \"Black\",\n",
      "                  \"Other\",\n",
      "                  \"White\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  329,\n",
      "                  1046,\n",
      "                  3362,\n",
      "                  240,\n",
      "                  29710\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Amer-Indian-Eskimo\",\n",
      "                  \"Asian-Pac-Islander\",\n",
      "                  \"Black\",\n",
      "                  \"Other\",\n",
      "                  \"White\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  141,\n",
      "                  473,\n",
      "                  1323,\n",
      "                  166,\n",
      "                  12052\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"relationship\": {\n",
      "            \"column_name\": \"relationship\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.007765049495800667,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Husband\",\n",
      "                  \"Not-in-family\",\n",
      "                  \"Other-relative\",\n",
      "                  \"Own-child\",\n",
      "                  \"Unmarried\",\n",
      "                  \"Wife\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  13682,\n",
      "                  9073,\n",
      "                  1038,\n",
      "                  5634,\n",
      "                  3604,\n",
      "                  1656\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Husband\",\n",
      "                  \"Not-in-family\",\n",
      "                  \"Other-relative\",\n",
      "                  \"Own-child\",\n",
      "                  \"Unmarried\",\n",
      "                  \"Wife\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  6034,\n",
      "                  3510,\n",
      "                  468,\n",
      "                  1947,\n",
      "                  1521,\n",
      "                  675\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"sex\": {\n",
      "            \"column_name\": \"sex\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.002874406423548237,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Female\",\n",
      "                  \"Male\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  11752,\n",
      "                  22935\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Female\",\n",
      "                  \"Male\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4440,\n",
      "                  9715\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"workclass\": {\n",
      "            \"column_name\": \"workclass\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.013185895855520359,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Federal-gov\",\n",
      "                  \"Local-gov\",\n",
      "                  \"Never-worked\",\n",
      "                  \"Private\",\n",
      "                  \"Self-emp-inc\",\n",
      "                  \"Self-emp-not-inc\",\n",
      "                  \"State-gov\",\n",
      "                  \"Without-pay\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1071,\n",
      "                  2050,\n",
      "                  4,\n",
      "                  24520,\n",
      "                  1176,\n",
      "                  2610,\n",
      "                  1336,\n",
      "                  17\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Federal-gov\",\n",
      "                  \"Local-gov\",\n",
      "                  \"Never-worked\",\n",
      "                  \"Private\",\n",
      "                  \"Self-emp-inc\",\n",
      "                  \"Self-emp-not-inc\",\n",
      "                  \"State-gov\",\n",
      "                  \"Without-pay\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  361,\n",
      "                  1086,\n",
      "                  6,\n",
      "                  9386,\n",
      "                  519,\n",
      "                  1252,\n",
      "                  645,\n",
      "                  4\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"current_fi\": null,\n",
      "        \"reference_fi\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"timestamp\": \"2024-10-21 12:13:34.206277\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_data = '[{\"ID\":10,\"Name\":\"Pankaj\",\"Role\":\"CEO\"},' \\\n",
    "            '{\"ID\":20,\"Name\":\"David Lee\",\"Role\":\"Editor\"}]'\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.options import ColorOptions\n",
    "from evidently.report import Report\n",
    "\n",
    "from evidently.metrics import ColumnDriftMetric\n",
    "from evidently.metrics import DataDriftTable\n",
    "from evidently.metrics import DatasetDriftMetric\n",
    "from evidently.metrics import ColumnCategoryMetric\n",
    "from evidently.metrics import ColumnDistributionMetric\n",
    "from evidently.metrics import ColumnValuePlot\n",
    "from evidently.metrics import ColumnQuantileMetric\n",
    "from evidently.metrics import ColumnCorrelationsMetric\n",
    "from evidently.metrics import ColumnValueListMetric\n",
    "from evidently.metrics import ColumnValueRangeMetric\n",
    "\n",
    "#Dataset for Data Quality and Integrity\n",
    "adult_data = datasets.fetch_openml(name='adult', version=2, as_frame=True)\n",
    "adult = adult_data.frame\n",
    "print(\"\\n -----> \", adult.shape)\n",
    "\n",
    "\n",
    "adult_ref = adult[~adult.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "adult_cur = adult[adult.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "\n",
    "#print(\"\\n =====> \", adult_ref)\n",
    "#print(\"\\n ******> \", adult_cur.shape)\n",
    "\n",
    "adult_cur.iloc[:2000, 3:5] = np.nan\n",
    "\n",
    "data_drift_dataset_report = Report(metrics=[\n",
    "    DataDriftTable(num_stattest='kl_div', cat_stattest='psi'),    \n",
    "])\n",
    "\n",
    "data_drift_dataset_report.run(reference_data=adult_ref, current_data=adult_cur)\n",
    "data_drift_dataset_report\n",
    "\n",
    "#report in a JSON format\n",
    "# data_drift_dataset_report.json()\n",
    "\n",
    "json_object = json.loads(data_drift_dataset_report.json())\n",
    "\n",
    "json_formatted_str = json.dumps(json_object, indent=2)\n",
    "\n",
    "print(json_formatted_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c181d55-082f-41ca-a57b-2d1c19d0cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " No rows were found with missing values\n",
      "\n",
      " No columns were found with missing values\n",
      "\n",
      " Percentage Drift:  10.6  -----Total images that had drift:  106\n",
      "\n",
      " **********  (1000, 784) 28\n",
      "Train Set\n",
      "(1000,)\n",
      "Test Set\n",
      "(1000, 784)\n",
      "(1000,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3680566/3874489084.py\u001b[0m in \u001b[0;36m<cell line: 599>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrimmed_train_dataset_ver1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0;31m#model.fit(X[train], y[train],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m               \u001b[0;31m#batch_size=128, epochs=2, validation_data=(X[test], y[test]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model metadata setting up \n",
    "# And splitting dataset for drift measures\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import DataDriftTable\n",
    "from evidently.metrics import DatasetDriftMetric\n",
    "from evidently.metrics import DatasetSummaryMetric\n",
    "from evidently.metrics import DatasetMissingValuesMetric\n",
    "#from evidently.metrics import DatasetCorrelationMetric\n",
    "from data_drift_detector import DataDriftDetector\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# from scikit-image.io import imread, imshow\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "        breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    " \n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    " \n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i])\n",
    "\n",
    "                                             for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        psi_values = psi(expected, actual, buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "\n",
    "# Trying a different PSI procedure\n",
    "def psi(reference, monitored, bins=None):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) between a reference dataset and a monitored dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    reference (numpy.array): The reference dataset, representing the baseline distribution.\n",
    "    monitored (numpy.array): The monitored dataset, representing the distribution to compare against the reference.\n",
    "    bins (int, optional): The number of bins to use for the histograms. If set to None, Doane's formula will be used to calculate the number of bins. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated PSI value. A higher value indicates greater divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    # Get the full dataset\n",
    "    full_dataset = np.concatenate((reference, monitored))\n",
    "\n",
    "    # If bins is not parametrized, use Doane's formula for calculating number of bins\n",
    "    if bins is None:\n",
    "        _, bin_edges = np.histogram(full_dataset, bins=\"doane\")\n",
    "    else:  # If number of bins is specified\n",
    "        bin_edges = np.linspace(min(min(reference), min(monitored)), max(max(reference), max(monitored)), bins + 1)\n",
    "\n",
    "    # Calculate the histogram for each dataset\n",
    "    reference_hist, _ = np.histogram(reference, bins=bin_edges)\n",
    "    monitored_hist, _ = np.histogram(monitored, bins=bin_edges)\n",
    "\n",
    "    # Convert histograms to proportions\n",
    "    reference_proportions = reference_hist / np.sum(reference_hist)\n",
    "    monitored_proportions = monitored_hist / np.sum(monitored_hist)\n",
    "\n",
    "    # Replace zeroes to avoid division by zero or log of zero errors\n",
    "    monitored_proportions = np.where(monitored_proportions == 0, 1e-6, monitored_proportions)\n",
    "    reference_proportions = np.where(reference_proportions == 0, 1e-6, reference_proportions)\n",
    "\n",
    "    # Calculate PSI\n",
    "    psi_values = (monitored_proportions - reference_proportions) * np.log(monitored_proportions / reference_proportions)\n",
    "    psi = np.sum(psi_values)\n",
    "\n",
    "    print(\"************* \", psi)\n",
    "\n",
    "    return psi\n",
    "\n",
    "## Calculate psi for features\n",
    "psi_list = []\n",
    "\n",
    "# top_feature_list=df_salary_high.columns\n",
    "'''\n",
    "for feature in range(len(train_images[0])): #top_feature_list:\n",
    "        # Assuming you have a validation and training set\n",
    "        #psi_t = calculate_psi( dataset_ver1[0][feature], train_images[0][feature])\n",
    "        # psi_t = psi( dataset_ver1[feature], train_images[feature])\n",
    "        psi_list.append(psi_t)      \n",
    "        print('Stability index for column ',feature,'is',psi_t)\n",
    "'''\n",
    "\n",
    "def dataset_ver_one (image):\n",
    "    return ndimage.prewitt(image, axis=0)\n",
    "    #return ds.filter(lambda x: x < 5)\n",
    "\n",
    "def dataset_ver_two (image):\n",
    "    return ndimage.prewitt(image, axis=1)\n",
    "    #return ds.filter(lambda x: x < 5)\n",
    "\n",
    "def dataset_ver_three (prewitt_h, prewitt_v):\n",
    "    magnitude = np.sqrt(prewitt_h ** 2 + prewitt_v ** 2)\n",
    "    magnitude *= 255 / np.max(magnitude)\n",
    "    return magnitude\n",
    "    # dimage.prewitt(ds[0], axis=1)\n",
    "    # return ds.filter(lambda x: x < 5)\n",
    "    \n",
    "def generate_dataset_from_mnist(train_images, train_labels):\n",
    "    new_dataset = train_images.apply(dataset_fn)\n",
    "    list(dataset.as_numpy_iterator())\n",
    "\n",
    "    \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# edges_prewitt_vertical = prewitt_v(train_images[0])\n",
    "dataset_ver1 = []\n",
    "dataset_ver2 = []\n",
    "dataset_ver3 = []\n",
    "dataset_ver4 = []\n",
    "dataset_transposed_ver = []\n",
    "dataset_corrupted_ver = []\n",
    "    \n",
    "\n",
    "def transpose_image(img):\n",
    "    kernel = np.zeros((28,28),np.uint8)\n",
    "    blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    return blackhat\n",
    "    \n",
    "    #imgT = img.T\n",
    "    # print(\"\\n Shape: \", imgT.shape)\n",
    "    #return imgT\n",
    "\n",
    "\n",
    "def corrupted_image(img):\n",
    "    \n",
    "    kernel = np.zeros((28,28),np.uint8)\n",
    "    tophat = cv2.morphologyEx(img, cv2. MORPH_TOPHAT, kernel) #\n",
    "\n",
    "    return tophat\n",
    "    \n",
    "\n",
    "def add_gaussian_noise(img):\n",
    "    gauss_noise=np.ones((28,28),dtype=np.uint8)\n",
    "    # We then use a random distribution to determine the pixel values \n",
    "    # of the noise (in this case with a mean of 128 and a sigma of 20)\n",
    "    cv2.randn(gauss_noise,18,2)\n",
    "    gauss_noise=(gauss_noise*10.5).astype(np.uint8)\n",
    "    gn_img=cv2.add(img,gauss_noise)\n",
    "    # print(\"\\n **************** \", gn_img)\n",
    "\n",
    "    return gn_img\n",
    "\n",
    "\n",
    "for t in range(len(train_images)):\n",
    "    prewitt_h = dataset_ver_one(train_images[t]) #, axis=0)\n",
    "    prewitt_v = dataset_ver_two(train_images[t]) #, axis=1)    \n",
    "    magnitude = dataset_ver_three(prewitt_h, prewitt_v)\n",
    "    gaussian = add_gaussian_noise(train_images[t])\n",
    "    transposedImg = transpose_image(train_images[t])\n",
    "    corrputedImg = corrupted_image(train_images[t])\n",
    "    \n",
    "    dataset_ver1.append(prewitt_h)\n",
    "    dataset_ver2.append(prewitt_v)\n",
    "    dataset_ver3.append(magnitude)\n",
    "    dataset_ver4.append(gaussian)\n",
    "    dataset_transposed_ver.append(transposedImg)\n",
    "    dataset_corrupted_ver.append(corrputedImg)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize = (8, 8))\n",
    "\n",
    "axes[0, 0].imshow(train_images[3000])\n",
    "# axes[0, 1].imshow(dataset_ver1[3000])\n",
    "# axes[0, 1].imshow(dataset_ver2[3000])\n",
    "axes[0, 1].imshow(dataset_corrupted_ver[3000])\n",
    "axes[1, 0].imshow(dataset_ver4[3000])\n",
    "axes[1, 1].imshow(dataset_transposed_ver[3000])\n",
    "plt.savefig(\"dataset_output\")\n",
    "\n",
    "titles = [\"original dataset\", \"dataset_ver2\", \"dataset_ver3\", \"dataset_ver4\", \"dataset_transposed\",\"dataset_corrupted\"]\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.set_title(titles[i])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def dataset_identifiers(titles):\n",
    "    dataset_idents = {}\n",
    "    \n",
    "    dataset_idents.update({titles[0]: dataset_ver1,\n",
    "                           titles[1]: dataset_ver2,\n",
    "                           titles[2]: dataset_ver3,\n",
    "                           titles[3]: dataset_ver4,\n",
    "                           titles[4]: dataset_transposed_ver,\n",
    "                           titles[5]: dataset_corrupted_ver,\n",
    "                          })\n",
    "\n",
    "    return dataset_idents\n",
    "    \n",
    "\n",
    "def get_report(reference_data, current_data):\n",
    "    data_drift_dataset_report = Report(metrics=[DatasetMissingValuesMetric(), ])\n",
    "\n",
    "    data_drift_dataset_report.run(reference_data=reference_data, current_data=current_data,  column_mapping=None) #\n",
    "    data_drift_dataset_report.save(\"current_dataset_report.json\")\n",
    "\n",
    "\n",
    "def print_metric():\n",
    "    # Load the JSON report\n",
    "    with open('current_dataset_report.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Accessing accuracy from the JSON report\n",
    "    num_missing_values = None\n",
    "    row_is_missing = False\n",
    "    col_is_missing = False\n",
    "    found_missing_entries = False\n",
    "    \n",
    "    metric_results = data['suite']['metric_results']\n",
    "    \n",
    "    for result in metric_results:                        \n",
    "        if 'current' in result:\n",
    "            tot_num_of_row = result['current'].get('number_of_rows')\n",
    "            tot_num_of_col = result['current'].get('number_of_columns')\n",
    "            \n",
    "            num_missing_values = result['current'].get('number_of_rows_with_missing_values') # .get('accuracy')\n",
    "            if num_missing_values > 0:\n",
    "                row_is_missing = True\n",
    "                perc_row = float(num_missing_values /tot_num_of_row)*100\n",
    "                print(\"\\n The following statistics about missing entries:: \", perc_row)\n",
    "                row_is_missing = True\n",
    "            else:\n",
    "                row_is_missing = False\n",
    "                print(\"\\n No rows were found with missing values\")\n",
    "\n",
    "            col_num_missing_values = result['current'].get('number_of_columns_with_missing_values') # .get('accuracy')            \n",
    "            if col_num_missing_values > 0:\n",
    "                col_is_missing = True\n",
    "                perc_col = float(col_num_missing_values/tot_num_of_col)*100\n",
    "                print(\"\\n The following statistics about missing entries:: \", perc_col)\n",
    "            else:\n",
    "                col_is_missing = False\n",
    "                print(\"\\n No columns were found with missing values\")\n",
    "\n",
    "    if row_is_missing or col_is_missing:\n",
    "        found_missing_entries = True\n",
    "\n",
    "    return found_missing_entries\n",
    "    \n",
    "    \n",
    "def get_drift_in_dataset(base_df,current_df)->bool: \n",
    "    status = True\n",
    "    report={}\n",
    "    threshold=0.05\n",
    "    for column in base_df.columns:\n",
    "        d1 = base_df[column]\n",
    "        d2 = current_df[column]\n",
    "        is_same_dist = ks_2samp(d1,d2)\n",
    "\n",
    "        if threshold<=is_same_dist.pvalue:\n",
    "            is_found=False\n",
    "        else:\n",
    "            status = False\n",
    "            is_found=True\n",
    "    \n",
    "    # print(\"p_value: \",float(is_same_dist.pvalue),\"drift_status: \",is_found) \n",
    "    #print(\"p_value: %2.25f --- drift_status: %s\" %(is_same_dist.pvalue,is_found)) #\" \", float(is_same_dist.pvalue)\n",
    "    return is_found #report\n",
    "\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28)\n",
    "\n",
    "#dataset_corrupted_ver = dataset_corrupted_ver.reshape(-1, 28 * 28)\n",
    "\n",
    "#print(\"\\n ***************** \", train_images[0], train_images[0].shape)\n",
    "#print(\"\\n Difference: \", dataset_corrupted_ver[0], dataset_corrupted_ver[0].shape)\n",
    "    \n",
    "count = 0                    \n",
    "for t in range(len(train_images)):\n",
    "    base_df =  pd.DataFrame(train_images[t]) # pd.DataFrame(t) #\n",
    "    current_df =  pd.DataFrame(dataset_corrupted_ver[t]) # pd.DataFrame(t) #\n",
    "    observed_drift = get_drift_in_dataset(base_df, current_df)  \n",
    "    get_report(base_df, current_df)\n",
    "    if observed_drift:\n",
    "        count = count + 1\n",
    "\n",
    "#dataset_metrics(train_images, dataset_corrupted_ver)\n",
    "print_metric()\n",
    "percent_drift_dataset = (count/len(train_images))*100\n",
    "\n",
    "print(\"\\n Percentage Drift: \", percent_drift_dataset, \" -----Total images that had drift: \", count)\n",
    "print(\"\\n ********** \", train_images.shape, len(dataset_ver1[0]))\n",
    "\n",
    "\n",
    "### - This is another attempt ################\n",
    "\n",
    "# To speed up these runs, use the first 1000 examples\n",
    "#train_labels = train_labels[:1000]\n",
    "#test_labels = test_labels[:1000]\n",
    "\n",
    "#train_images = train_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "#test_images = test_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "\n",
    "trimmed_train_dataset_ver1 = dataset_ver1[:1000]\n",
    "\n",
    "\n",
    "def generate_dataset_with_attributes(dataset):\n",
    "    import datetime\n",
    "    dataset_timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    dataset_attr = {}\n",
    "    datasetID = titles.get(dataset)\n",
    "    version = datasetID+\"_\"+dataset_timestamp\n",
    "    \n",
    "    empties_found = print_metric()    \n",
    "    publisher = \"DFKI\"\n",
    "    checksum = get_dataset_checksum(dataset)\n",
    "    attr = [datasetID, dataset_timestamp, publisher, checksum, empties_found, percent_drift_dataset]\n",
    "    \n",
    "    dataset_attr.update({version:attr})\n",
    "    \n",
    "    return dataset_attr\n",
    "\n",
    "\n",
    "'''    \n",
    "    We use the gini index to measure the spasrity in the weights\n",
    "    Sparsity: if weight norm (\"average\") is low, the model is sparse. May or may not be beneficial.\n",
    "'''\n",
    "\n",
    "def get_weight_sparsity(model, w=None):\n",
    "    # The rest of the code requires numpy arrays.\n",
    "    input_layer, hidden_layer, output_layer = get_model_internals(model)\n",
    "    all_layer = [input_layer,hidden_layer,output_layer]\n",
    "    sparse_measure = 0.0\n",
    "    t = []\n",
    "\n",
    "    for layer in all_layers:\n",
    "        x = np.asarray(layer)\n",
    "        if w is not None:\n",
    "            w = np.asarray(w)\n",
    "            sorted_indices = np.argsort(x)\n",
    "            sorted_x = x[sorted_indices]\n",
    "            sorted_w = w[sorted_indices]\n",
    "            # Force float dtype to avoid overflows\n",
    "            cumw = np.cumsum(sorted_w, dtype=float)\n",
    "            cumxw = np.cumsum(sorted_x * sorted_w, dtype=float)\n",
    "            return (np.sum(cumxw[1:] * cumw[:-1] - cumxw[:-1] * cumw[1:]) / \n",
    "                (cumxw[-1] * cumw[-1]))\n",
    "        else:\n",
    "            sorted_x = np.sort(x)\n",
    "            n = len(x)\n",
    "            cumx = np.cumsum(sorted_x, dtype=float)\n",
    "            # The above formula, with all weights equal to 1 simplifies to:\n",
    "            #return (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "            t[layers] = (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "\n",
    "    return float(np.sum(t)/len(all_layers))\n",
    "    \n",
    "\n",
    "def get_dataset_checksum(dataset_file):\n",
    "    import hashlib\n",
    "    checksum = hashlib.md5(open(dataset_file,'rb').read()).hexdigest()\n",
    "\n",
    "    return checksum\n",
    "    \n",
    "    \n",
    "def get_model_weights_analysis(model):\n",
    "    '''\n",
    "        1.  get weight stability by avergaing over the weights across different layers\n",
    "            This will give some kind of variance, std-dev, decay rate parameter\n",
    "            the distribution of this weight decay is then an exponential distrobution\n",
    "            The rate parameter of this distribution is then the measure of the sparsity of the weights\n",
    "        2. Then we need another measure for the health of the weights\n",
    "        3. And another measure for the weight sparsity - 3 and 2 carry less weight than 1 in the fitness algorithm\n",
    "\n",
    "        This procedure returns these as coefficients \n",
    "    '''\n",
    "\n",
    "    num_trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "\n",
    "    nonzero_threshold = 60\n",
    "    health_status = False\n",
    "    total_parameters = 0\n",
    "    \n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(shape)\n",
    "        print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)\n",
    "\n",
    "    nonzero_parameters = np.sum([np.count_nonzero(var) for var in total_parameters])\n",
    "\n",
    "    percent_nonzeros = float(nonzero_parameters/total_parameters) * 100\n",
    "    \n",
    "    health_status = True if percent_nonzeros > nonzero_threshold else False\n",
    "    \n",
    "\n",
    "def get_layers_in_NN(model):\n",
    "\n",
    "    conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "\n",
    "    return model.layers\n",
    "    \n",
    "\n",
    "def print_stats(nparray):\n",
    "    print(\"Shape: \", nparray.shape)\n",
    "    print(\"Mean: \", np.mean(nparray))\n",
    "    print(\"Standard Deviation: \", np.std(nparray))\n",
    "    print(\"Variance: \", np.var(nparray))\n",
    "    print(\"Min: \", np.min(nparray))\n",
    "    print(\"Max: \", np.max(nparray))\n",
    "\n",
    "\n",
    "def plot_histo(nparray, model_name, layer, param):\n",
    "    assert param in {'weights', 'biases'}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(np.asarray(nparray).flatten(), rwidth=0.9)\n",
    "    plt.title(f\"Plot of {model_name} {param} in {layer} layer\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "\n",
    "def summarize(nparray, model_name=None, layer=None, param=None):\n",
    "    print_stats(nparray)\n",
    "    plot_histo(nparray, model_name, layer, param)\n",
    "\n",
    "\n",
    "def get_weight_sums(conv_layers):\n",
    "    weight_sums = []\n",
    "    for conv_layer in conv_layers:\n",
    "        weights = conv_layer.get_weights()[0]\n",
    "        weight_sums.append(sum(sum(sum(sum(abs(weights / weights.size))))))\n",
    "    return weight_sums\n",
    "\n",
    "\n",
    "def plot_layer_mean_weight(weight_sums, model):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(range(len(weight_sums)), weight_sums)\n",
    "    plt.title(f\"Weight changing by layer in {model}\")\n",
    "    plt.ylabel(\"Mean of absolute value of weight\")\n",
    "    plt.xlabel(\"Convolutional layer number\")\n",
    "\n",
    "\n",
    "def get_decaying_rate(weight_sums):\n",
    "\n",
    "    decay_rate = 0.0\n",
    "    summed = 0.0\n",
    "    \n",
    "    for weigh in weight_sums:\n",
    "        summed = summed + float(1/weigh)\n",
    "\n",
    "    decay_rate = summed/len(weight_sums)\n",
    "\n",
    "    return decay_rate\n",
    "\n",
    "\n",
    "def get_model_internals(model):\n",
    "    \n",
    "    W = [], U = [], b = []\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        W.append(model.layers[layer].get_weights()[0])\n",
    "        U.append(model.layers[layer].get_weights()[1])\n",
    "        b.append(model.layers[layer].get_weights()[2])\n",
    "\n",
    "    return W, U, b\n",
    "\n",
    "\n",
    "def generate_model_with_attributes(model):\n",
    "    import tf2onnx\n",
    "    import onnx\n",
    "\n",
    "    input_signature = [tf.TensorSpec([3, 3], tf.float32, name='x')]\n",
    "    # Use from_function for tf functions\n",
    "    \n",
    "    onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=13)\n",
    "    # onnx.save(onnx_model, \"dst/path/model.onnx\")\n",
    "    model_owner = \"DFKI\"\n",
    "\n",
    "    weight_profile = {'health': get_model_weights_analysis(model), 'sparsity': get_weight_sparsity(model), 'stability': get_decaying_rate(weight_sums)}\n",
    "\n",
    "    dataset_profile = generate_dataset_with_attributes()\n",
    "\n",
    "    attr1 = onnx_model.metadata_props.add()\n",
    "    attr1.key = 'weight_stats'\n",
    "    attr1.value = json.dumps(weight_profile)\n",
    "\n",
    "    # we take the domain to be the class of the actual task at hand\n",
    "    attr2 = onnx_model.metadata_props.add()\n",
    "    attr2.key = 'domain'\n",
    "    attr2.value = json.dumps(\"ml.task.image-classification\")\n",
    "\n",
    "    attr3 = onnx_model.metadata_props.add()\n",
    "    attr3.key = 'model_version'\n",
    "    attr3.value = json.dumps(model_ver)\n",
    "\n",
    "    attr4 = onnx_model.metadata_props.add()\n",
    "    attr4.key = 'producer_name'\n",
    "    attr4.value = json.dumps(model_owner)\n",
    "\n",
    "    attr5 = onnx_model.metadata_props.add()\n",
    "    attr5.key = 'dataset_properties'\n",
    "    attr5.value = json.dumps(dataset_profile)\n",
    "\n",
    "    onnx.save(onnx_model, 'deeplabv3_landcover_4c.onnx')\n",
    "\n",
    "    #print(\"doc_string={}\".format(model.doc_string))\n",
    "    #print(\"domain={}\".format(model.domain))\n",
    "    #print(\"ir_version={}\".format(model.ir_version))\n",
    "    #print(\"metadata_props={}\".format(model.metadata_props))\n",
    "    #print(\"model_version={}\".format(model.model_version))\n",
    "    #print(\"producer_name={}\".format(model.producer_name))\n",
    "\n",
    "    # model_attributes = {}\n",
    "\n",
    "\n",
    "'''\n",
    "    Now we try to train the models\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import apache_beam as beam\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "# print(\"\\n MODEL => \", model)\n",
    "\n",
    "# print(\"\\n ==========> \", trimmed_train_dataset_ver1.shape)\n",
    "\n",
    "#for kfold, (train, test) in enumerate(KFold(n_splits=3, shuffle=True).split(train_images, train_labels)): #split(X, y)):\n",
    "\n",
    "for kfold, (train, test) in enumerate(KFold(n_splits=3, shuffle=True).split(trimmed_train_dataset_ver1, train_labels)): #split(X, y)):\n",
    "    # clear the session \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # calling the model and compile it \n",
    "    #seq_model = my_model()\n",
    "    model.compile(\n",
    "        loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics  = tf.keras.metrics.CategoricalAccuracy(),\n",
    "        optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "    print('Train Set')\n",
    "    #print(train_images.shape)\n",
    "    #print(dataset_ver1.shape)\n",
    "    print(train_labels.shape)\n",
    "\n",
    "    print('Test Set')\n",
    "    print(test_images.shape)\n",
    "    print(test_labels.shape)\n",
    "\n",
    "    # run the model \n",
    "    model.fit(trimmed_train_dataset_ver1[train], train_labels[train],batch_size=128, epochs=20, validation_data=(test_images[test], test_labels[test]))\n",
    "    #model.fit(X[train], y[train],\n",
    "              #batch_size=128, epochs=2, validation_data=(X[test], y[test]))\n",
    "    \n",
    "    model.save_weights(f'wg_{kfold}.h5')\n",
    "\n",
    "# Display the model's architecture\n",
    "print(\"\\n ****************** Model Arch *************************** \\n\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# The tf.keras.callbacks.ModelCheckpoint callback allows you to continually \n",
    "# save the model both during and at the end of training\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(X[train], \n",
    "          y[train],  \n",
    "          epochs=10,\n",
    "          validation_data=(X[test], y[test]),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "filepath = \"/home/antillas/collabos/model_aggregation\"\n",
    "\n",
    "# Save all The model's configuration (architecture), The model's weights, \n",
    "# Saves a model as a .keras file - The model's optimizer's state (if any)\n",
    "\n",
    "model.save(\"kera_model_one.keras\")\n",
    "\n",
    "# Saves all layer weights to a .weights.h5 file.\n",
    "model.save_weights(\n",
    "    filepath, overwrite=True\n",
    ")\n",
    "\n",
    "\n",
    "def generate_model_metadata(model):\n",
    "    custom_attr = tf.Variable(['custom_att1', 'custom_att2'])\n",
    "\n",
    "\n",
    "conv_layers = get_layers_in_NN(model)\n",
    "weight_sums = get_weight_sums(conv_layers)\n",
    "decaying_rate = get_decaying_rate(weight_sums)\n",
    "print(\"\\n Decaying rate: \", decaying_rate)\n",
    "\n",
    "plot_layer_mean_weight(weight_sums, 'VGG-16')\n",
    "\n",
    "\n",
    "# What we want to accomplish\n",
    "# Next steps for the \n",
    "'''\n",
    "1: Use the metadat extractor here to retrieve any metadata about the pretrained models\n",
    "\n",
    "2: A component for the metadata schema validator\n",
    "\n",
    "3: Give weights to each model metadata -> Kind of a fitnesss functions\n",
    "\n",
    "4: Encode metadata as chromosomes\n",
    "\n",
    "5: Do generic algorithm for Model aggregation\n",
    "\n",
    "6: Do FedAvg aggregations, Bagging/stacking/Voting\n",
    "\n",
    "7: Compare results from 5 to results from 6\n",
    "'''\n",
    "\n",
    "'''\n",
    "  FedAvg - Load pretrained models and do aggregations - mobilenet models\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6b558-b44c-43ef-93e2-8b2c46e3ffab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
