{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed8c94-fe42-46ba-915a-de9a5768358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.94 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "# loading iris dataset \n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "# Voting Classifier with hard voting \n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "# Ensemble of Models \n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "#estimator = [] \n",
    "#estimator.append(('LR',LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200))) \n",
    "#estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
    "# estimator.append(('DTC', DecisionTreeClassifier())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd241f32-f1d7-47c6-8be3-ad66dddb83df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3128285/2738165774.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# calling the model and compile it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mseq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     seq_model.compile(\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "# More Model ensembling techniques now #\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Loading some example data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 2])\n",
    "\n",
    "clf1 = clf1.fit(X, y)\n",
    "clf2 = clf2.fit(X, y)\n",
    "clf3 = clf3.fit(X, y)\n",
    "eclf = eclf.fit(X, y)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Deicision Tree', 'K-Nearest Neighbour', 'SVC', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7269cc0d-a529-4233-8375-0c32fe023f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "(100, 2)\n",
      "(100,)\n",
      "Test Set\n",
      "(50, 2)\n",
      "(50,)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3128285/4189055219.py\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     model.fit(X[train], y[train],\n\u001b[0m\u001b[1;32m     63\u001b[0m               batch_size=128, epochs=2, validation_data=(X[test], y[test]))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Now we want to analyse the models using tfma \n",
    "# This setup was tested with TF 2.10 and TFMA 0.41 (using colab), but it should\n",
    "# also work with the latest release.\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Confirm that we're using Python 3\n",
    "assert sys.version_info.major==3, 'This notebook must be run using Python 3.'\n",
    "\n",
    "import tensorflow as tf\n",
    "# print('TF version: {}'.format(tf.__version__))\n",
    "# import apache_beam as beam\n",
    "#print('Beam version: {}'.format(beam.__version__))\n",
    "import tensorflow_model_analysis as tfma\n",
    "# print('TFMA version: {}'.format(tfma.__version__))\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(2,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "for kfold, (train, test) in enumerate(KFold(n_splits=3, \n",
    "                                shuffle=True).split(X, y)):\n",
    "    # clear the session \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # calling the model and compile it \n",
    "    #seq_model = my_model()\n",
    "    model.compile(\n",
    "        loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics  = tf.keras.metrics.CategoricalAccuracy(),\n",
    "        optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "    print('Train Set')\n",
    "    print(X[train].shape)\n",
    "    print(y[train].shape)\n",
    "\n",
    "    print('Test Set')\n",
    "    print(X[test].shape)\n",
    "    print(y[test].shape)\n",
    "\n",
    "    # run the model \n",
    "    model.fit(X[train], y[train],\n",
    "              batch_size=128, epochs=2, validation_data=(X[test], y[test]))\n",
    "    \n",
    "    model.save_weights(f'wg_{kfold}.h5')\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# The tf.keras.callbacks.ModelCheckpoint callback allows you to continually \n",
    "# save the model both during and at the end of training\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(X[train], \n",
    "          y[train],  \n",
    "          epochs=10,\n",
    "          validation_data=(X[test], y[test]),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "filepath = \"/home/antillas/collabos/model_aggregation\"\n",
    "\n",
    "# Save all The model's configuration (architecture), The model's weights, \n",
    "# Saves a model as a .keras file - The model's optimizer's state (if any)\n",
    "\n",
    "model.save(\"kera_model_one.keras\")\n",
    "\n",
    "# Saves all layer weights to a .weights.h5 file.\n",
    "model.save_weights(\n",
    "    filepath, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa96d0a-273f-4f54-9da7-5159329a55cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1006610/4155883061.py\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_federated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# the directory structure. The python import statements above implicitly add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# these to locals().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpython\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mproto\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "# Next steps for the \n",
    "'''\n",
    "1: Use the metadat extractor here to retrieve any metadata about the pretrained models\n",
    "\n",
    "2: A component for the metadata schema validator\n",
    "\n",
    "3: Give weights to each model metadata -> Kind of a fitnesss functions\n",
    "\n",
    "4: Encode metadata as chromosomes\n",
    "\n",
    "5: Do generic algorithm for Model aggregation\n",
    "\n",
    "6: Do FedAvg aggregations, Bagging/stacking/Voting\n",
    "\n",
    "7: Compare results from 5 to results from 6\n",
    "'''\n",
    "\n",
    "'''\n",
    "  FedAvg - Load pretrained models and do aggregations - mobilenet models\n",
    "'''\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "!pip install tf-keras==2.15.0\n",
    "!pip install tensorflow==2.15.2\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  # Get pre-trained mobileNet models \n",
    "  keras_model = timm.create_model('mobilenetv4_hybrid_large.ix_e600_r384_in1k', pretrained=True, features_only=True,)\n",
    "    \n",
    "  # keras_model = create_keras_model()\n",
    "  return tff.learning.models.from_keras_model(\n",
    "      keras_model,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "if \"__name__\" == main:\n",
    "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "        model_fn,\n",
    "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "\n",
    "    print(training_process.initialize.type_signature.formatted_representation())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53e7f6bc-e6da-4677-aa99-26d7d37be063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----->  (48842, 15)\n",
      "{\n",
      "  \"version\": \"0.4.37\",\n",
      "  \"metrics\": [\n",
      "    {\n",
      "      \"metric\": \"DataDriftTable\",\n",
      "      \"result\": {\n",
      "        \"number_of_columns\": 15,\n",
      "        \"number_of_drifted_columns\": 3,\n",
      "        \"share_of_drifted_columns\": 0.2,\n",
      "        \"dataset_drift\": false,\n",
      "        \"drift_by_columns\": {\n",
      "          \"age\": {\n",
      "            \"column_name\": \"age\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.02723374709437682,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  17.0,\n",
      "                  24.3,\n",
      "                  31.6,\n",
      "                  38.9,\n",
      "                  46.2,\n",
      "                  53.5,\n",
      "                  60.8,\n",
      "                  68.1,\n",
      "                  75.4,\n",
      "                  82.7,\n",
      "                  90.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.02471021672878118,\n",
      "                  0.025839691234843417,\n",
      "                  0.0262859521410848,\n",
      "                  0.025211766596857754,\n",
      "                  0.015942967066340047,\n",
      "                  0.010173168977679455,\n",
      "                  0.0061528716099474344,\n",
      "                  0.0018640278561586543,\n",
      "                  0.000568686464590777,\n",
      "                  0.0002369526935794904\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  17.0,\n",
      "                  24.3,\n",
      "                  31.6,\n",
      "                  38.9,\n",
      "                  46.2,\n",
      "                  53.5,\n",
      "                  60.8,\n",
      "                  68.1,\n",
      "                  75.4,\n",
      "                  82.7,\n",
      "                  90.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.02104876054252575,\n",
      "                  0.020739077628796638,\n",
      "                  0.02384558435714183,\n",
      "                  0.026835959992838568,\n",
      "                  0.018658395552179158,\n",
      "                  0.012580868370245284,\n",
      "                  0.00869047676652328,\n",
      "                  0.0029516652714806184,\n",
      "                  0.001287119610186633,\n",
      "                  0.000348393277945254\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"capital-gain\": {\n",
      "            \"column_name\": \"capital-gain\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.02138191945976756,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  9999.9,\n",
      "                  19999.8,\n",
      "                  29999.699999999997,\n",
      "                  39999.6,\n",
      "                  49999.5,\n",
      "                  59999.399999999994,\n",
      "                  69999.3,\n",
      "                  79999.2,\n",
      "                  89999.09999999999,\n",
      "                  99999.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  9.822510079686088e-05,\n",
      "                  1.2569676248842519e-06,\n",
      "                  1.7297719608498882e-07,\n",
      "                  1.1531813072332584e-08,\n",
      "                  2.882953268083146e-09,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  3.3153962582956155e-07\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  9999.9,\n",
      "                  19999.8,\n",
      "                  29999.699999999997,\n",
      "                  39999.6,\n",
      "                  49999.5,\n",
      "                  59999.399999999994,\n",
      "                  69999.3,\n",
      "                  79999.2,\n",
      "                  89999.09999999999,\n",
      "                  99999.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  9.634147913361861e-05,\n",
      "                  2.2395137409516095e-06,\n",
      "                  4.804004239265283e-07,\n",
      "                  1.4129424233133181e-08,\n",
      "                  1.4129424233133181e-08,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  9.113478630370894e-07\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"capital-loss\": {\n",
      "            \"column_name\": \"capital-loss\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.0027433051180048777,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  435.6,\n",
      "                  871.2,\n",
      "                  1306.8000000000002,\n",
      "                  1742.4,\n",
      "                  2178.0,\n",
      "                  2613.6000000000004,\n",
      "                  3049.2000000000003,\n",
      "                  3484.8,\n",
      "                  3920.4,\n",
      "                  4356.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.0021929683487458603,\n",
      "                  1.1912910903101098e-06,\n",
      "                  1.257473928660671e-06,\n",
      "                  3.4745990134044877e-05,\n",
      "                  5.201971094354147e-05,\n",
      "                  1.2310007933204457e-05,\n",
      "                  5.95645545155055e-07,\n",
      "                  6.618283835056166e-08,\n",
      "                  3.309141917528083e-07,\n",
      "                  1.98548515051685e-07\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  0.0,\n",
      "                  390.0,\n",
      "                  780.0,\n",
      "                  1170.0,\n",
      "                  1560.0,\n",
      "                  1950.0,\n",
      "                  2340.0,\n",
      "                  2730.0,\n",
      "                  3120.0,\n",
      "                  3510.0,\n",
      "                  3900.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.002434221847856606,\n",
      "                  1.0868679183762194e-06,\n",
      "                  1.2680125714389225e-06,\n",
      "                  7.970364734758943e-06,\n",
      "                  6.23137606535699e-05,\n",
      "                  3.967067902073201e-05,\n",
      "                  1.4672716898078962e-05,\n",
      "                  2.173735836752439e-06,\n",
      "                  1.811446530627032e-07,\n",
      "                  5.434339591881097e-07\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"education-num\": {\n",
      "            \"column_name\": \"education-num\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 6.873706387420469,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  9.0,\n",
      "                  9.4,\n",
      "                  9.8,\n",
      "                  10.2,\n",
      "                  10.6,\n",
      "                  11.0,\n",
      "                  11.4,\n",
      "                  11.8,\n",
      "                  12.2,\n",
      "                  12.6,\n",
      "                  13.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1.138984917551319,\n",
      "                  0.0,\n",
      "                  0.7847156361856423,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.0,\n",
      "                  0.5762994462630397\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  2.5,\n",
      "                  4.0,\n",
      "                  5.5,\n",
      "                  7.0,\n",
      "                  8.5,\n",
      "                  10.0,\n",
      "                  11.5,\n",
      "                  13.0,\n",
      "                  14.5,\n",
      "                  16.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.015542211232779936,\n",
      "                  0.023972683386318142,\n",
      "                  0.08058401036147415,\n",
      "                  0.06541858000706464,\n",
      "                  0.11628399858707171,\n",
      "                  0.0,\n",
      "                  0.09706817379018015,\n",
      "                  0.07540327328388084,\n",
      "                  0.12513834922877665,\n",
      "                  0.06725538678912045\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"fnlwgt\": {\n",
      "            \"column_name\": \"fnlwgt\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.001663513925995391,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  12285.0,\n",
      "                  160096.5,\n",
      "                  307908.0,\n",
      "                  455719.5,\n",
      "                  603531.0,\n",
      "                  751342.5,\n",
      "                  899154.0,\n",
      "                  1046965.5,\n",
      "                  1194777.0,\n",
      "                  1342588.5,\n",
      "                  1490400.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  2.7682113067215177e-06,\n",
      "                  3.1635586130503076e-06,\n",
      "                  7.115081270288237e-07,\n",
      "                  9.166908434856009e-08,\n",
      "                  2.184454775965687e-08,\n",
      "                  4.2908933099325996e-09,\n",
      "                  2.340487259963236e-09,\n",
      "                  1.170243629981618e-09,\n",
      "                  3.900812099938727e-10,\n",
      "                  3.900812099938727e-10\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  13769.0,\n",
      "                  157935.6,\n",
      "                  302102.2,\n",
      "                  446268.80000000005,\n",
      "                  590435.4,\n",
      "                  734602.0,\n",
      "                  878768.6000000001,\n",
      "                  1022935.2000000001,\n",
      "                  1167101.8,\n",
      "                  1311268.4000000001,\n",
      "                  1455435.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  2.7559464969112866e-06,\n",
      "                  3.229318530342351e-06,\n",
      "                  8.061045496833332e-07,\n",
      "                  1.1172756068559274e-07,\n",
      "                  2.1561459079675788e-08,\n",
      "                  8.330563735329276e-09,\n",
      "                  9.80066321803445e-10,\n",
      "                  9.80066321803445e-10,\n",
      "                  4.900331609017221e-10,\n",
      "                  9.80066321803446e-10\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"hours-per-week\": {\n",
      "            \"column_name\": \"hours-per-week\",\n",
      "            \"column_type\": \"num\",\n",
      "            \"stattest_name\": \"Kullback-Leibler divergence\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.008522799705411234,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  10.8,\n",
      "                  20.6,\n",
      "                  30.400000000000002,\n",
      "                  40.2,\n",
      "                  50.0,\n",
      "                  59.800000000000004,\n",
      "                  69.60000000000001,\n",
      "                  79.4,\n",
      "                  89.2,\n",
      "                  99.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.0020562899821905873,\n",
      "                  0.006445395351902112,\n",
      "                  0.007127883586334467,\n",
      "                  0.0567789026412883,\n",
      "                  0.009940205793736761,\n",
      "                  0.012011204574083209,\n",
      "                  0.005336351970949533,\n",
      "                  0.0013620347092335367,\n",
      "                  0.0006089442436530068,\n",
      "                  0.0003736034731590911\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  1.0,\n",
      "                  10.8,\n",
      "                  20.6,\n",
      "                  30.400000000000002,\n",
      "                  40.2,\n",
      "                  50.0,\n",
      "                  59.800000000000004,\n",
      "                  69.60000000000001,\n",
      "                  79.4,\n",
      "                  89.2,\n",
      "                  99.0\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0.003070956393860971,\n",
      "                  0.008196425868121887,\n",
      "                  0.007028597380315601,\n",
      "                  0.05289830520692911,\n",
      "                  0.009313792631146421,\n",
      "                  0.012579387106308432,\n",
      "                  0.005968901159898786,\n",
      "                  0.001585939921712239,\n",
      "                  0.0007785523252041899,\n",
      "                  0.0006199583330329661\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"class\": {\n",
      "            \"column_name\": \"class\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.009418183755514647,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"<=50K\",\n",
      "                  \">50K\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  26808,\n",
      "                  7879\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"<=50K\",\n",
      "                  \">50K\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  10347,\n",
      "                  3808\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"education\": {\n",
      "            \"column_name\": \"education\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 15.016729259060078,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"10th\",\n",
      "                  \"11th\",\n",
      "                  \"12th\",\n",
      "                  \"1st-4th\",\n",
      "                  \"5th-6th\",\n",
      "                  \"7th-8th\",\n",
      "                  \"9th\",\n",
      "                  \"Assoc-acdm\",\n",
      "                  \"Assoc-voc\",\n",
      "                  \"Bachelors\",\n",
      "                  \"Doctorate\",\n",
      "                  \"HS-grad\",\n",
      "                  \"Masters\",\n",
      "                  \"Preschool\",\n",
      "                  \"Prof-school\",\n",
      "                  \"Some-college\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  7535,\n",
      "                  0,\n",
      "                  14892,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  10260\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"10th\",\n",
      "                  \"11th\",\n",
      "                  \"12th\",\n",
      "                  \"1st-4th\",\n",
      "                  \"5th-6th\",\n",
      "                  \"7th-8th\",\n",
      "                  \"9th\",\n",
      "                  \"Assoc-acdm\",\n",
      "                  \"Assoc-voc\",\n",
      "                  \"Bachelors\",\n",
      "                  \"Doctorate\",\n",
      "                  \"HS-grad\",\n",
      "                  \"Masters\",\n",
      "                  \"Preschool\",\n",
      "                  \"Prof-school\",\n",
      "                  \"Some-college\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1389,\n",
      "                  1812,\n",
      "                  657,\n",
      "                  247,\n",
      "                  509,\n",
      "                  955,\n",
      "                  756,\n",
      "                  1601,\n",
      "                  2061,\n",
      "                  0,\n",
      "                  594,\n",
      "                  0,\n",
      "                  2657,\n",
      "                  83,\n",
      "                  834,\n",
      "                  0\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"marital-status\": {\n",
      "            \"column_name\": \"marital-status\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.010266569095702678,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Divorced\",\n",
      "                  \"Married-AF-spouse\",\n",
      "                  \"Married-civ-spouse\",\n",
      "                  \"Married-spouse-absent\",\n",
      "                  \"Never-married\",\n",
      "                  \"Separated\",\n",
      "                  \"Widowed\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4819,\n",
      "                  30,\n",
      "                  15558,\n",
      "                  406,\n",
      "                  11805,\n",
      "                  1060,\n",
      "                  1009\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Divorced\",\n",
      "                  \"Married-AF-spouse\",\n",
      "                  \"Married-civ-spouse\",\n",
      "                  \"Married-spouse-absent\",\n",
      "                  \"Never-married\",\n",
      "                  \"Separated\",\n",
      "                  \"Widowed\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1814,\n",
      "                  7,\n",
      "                  6821,\n",
      "                  222,\n",
      "                  4312,\n",
      "                  470,\n",
      "                  509\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"native-country\": {\n",
      "            \"column_name\": \"native-country\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.09983207386210956,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Cambodia\",\n",
      "                  \"Canada\",\n",
      "                  \"China\",\n",
      "                  \"Columbia\",\n",
      "                  \"Cuba\",\n",
      "                  \"Dominican-Republic\",\n",
      "                  \"Ecuador\",\n",
      "                  \"El-Salvador\",\n",
      "                  \"England\",\n",
      "                  \"France\",\n",
      "                  \"Germany\",\n",
      "                  \"Greece\",\n",
      "                  \"Guatemala\",\n",
      "                  \"Haiti\",\n",
      "                  \"Holand-Netherlands\",\n",
      "                  \"Honduras\",\n",
      "                  \"Hong\",\n",
      "                  \"Hungary\",\n",
      "                  \"India\",\n",
      "                  \"Iran\",\n",
      "                  \"Ireland\",\n",
      "                  \"Italy\",\n",
      "                  \"Jamaica\",\n",
      "                  \"Japan\",\n",
      "                  \"Laos\",\n",
      "                  \"Mexico\",\n",
      "                  \"Nicaragua\",\n",
      "                  \"Outlying-US(Guam-USVI-etc)\",\n",
      "                  \"Peru\",\n",
      "                  \"Philippines\",\n",
      "                  \"Poland\",\n",
      "                  \"Portugal\",\n",
      "                  \"Puerto-Rico\",\n",
      "                  \"Scotland\",\n",
      "                  \"South\",\n",
      "                  \"Taiwan\",\n",
      "                  \"Thailand\",\n",
      "                  \"Trinadad&Tobago\",\n",
      "                  \"United-States\",\n",
      "                  \"Vietnam\",\n",
      "                  \"Yugoslavia\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  22,\n",
      "                  123,\n",
      "                  66,\n",
      "                  51,\n",
      "                  74,\n",
      "                  45,\n",
      "                  30,\n",
      "                  60,\n",
      "                  86,\n",
      "                  22,\n",
      "                  147,\n",
      "                  30,\n",
      "                  29,\n",
      "                  46,\n",
      "                  1,\n",
      "                  12,\n",
      "                  14,\n",
      "                  13,\n",
      "                  63,\n",
      "                  37,\n",
      "                  28,\n",
      "                  56,\n",
      "                  75,\n",
      "                  68,\n",
      "                  13,\n",
      "                  312,\n",
      "                  31,\n",
      "                  18,\n",
      "                  34,\n",
      "                  216,\n",
      "                  57,\n",
      "                  27,\n",
      "                  116,\n",
      "                  16,\n",
      "                  91,\n",
      "                  33,\n",
      "                  19,\n",
      "                  16,\n",
      "                  31848,\n",
      "                  63,\n",
      "                  16\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Cambodia\",\n",
      "                  \"Canada\",\n",
      "                  \"China\",\n",
      "                  \"Columbia\",\n",
      "                  \"Cuba\",\n",
      "                  \"Dominican-Republic\",\n",
      "                  \"Ecuador\",\n",
      "                  \"El-Salvador\",\n",
      "                  \"England\",\n",
      "                  \"France\",\n",
      "                  \"Germany\",\n",
      "                  \"Greece\",\n",
      "                  \"Guatemala\",\n",
      "                  \"Haiti\",\n",
      "                  \"Holand-Netherlands\",\n",
      "                  \"Honduras\",\n",
      "                  \"Hong\",\n",
      "                  \"Hungary\",\n",
      "                  \"India\",\n",
      "                  \"Iran\",\n",
      "                  \"Ireland\",\n",
      "                  \"Italy\",\n",
      "                  \"Jamaica\",\n",
      "                  \"Japan\",\n",
      "                  \"Laos\",\n",
      "                  \"Mexico\",\n",
      "                  \"Nicaragua\",\n",
      "                  \"Outlying-US(Guam-USVI-etc)\",\n",
      "                  \"Peru\",\n",
      "                  \"Philippines\",\n",
      "                  \"Poland\",\n",
      "                  \"Portugal\",\n",
      "                  \"Puerto-Rico\",\n",
      "                  \"Scotland\",\n",
      "                  \"South\",\n",
      "                  \"Taiwan\",\n",
      "                  \"Thailand\",\n",
      "                  \"Trinadad&Tobago\",\n",
      "                  \"United-States\",\n",
      "                  \"Vietnam\",\n",
      "                  \"Yugoslavia\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  6,\n",
      "                  59,\n",
      "                  56,\n",
      "                  34,\n",
      "                  64,\n",
      "                  58,\n",
      "                  15,\n",
      "                  95,\n",
      "                  41,\n",
      "                  16,\n",
      "                  59,\n",
      "                  19,\n",
      "                  59,\n",
      "                  29,\n",
      "                  0,\n",
      "                  8,\n",
      "                  16,\n",
      "                  6,\n",
      "                  88,\n",
      "                  22,\n",
      "                  9,\n",
      "                  49,\n",
      "                  31,\n",
      "                  24,\n",
      "                  10,\n",
      "                  639,\n",
      "                  18,\n",
      "                  5,\n",
      "                  12,\n",
      "                  79,\n",
      "                  30,\n",
      "                  40,\n",
      "                  68,\n",
      "                  5,\n",
      "                  24,\n",
      "                  32,\n",
      "                  11,\n",
      "                  11,\n",
      "                  11984,\n",
      "                  23,\n",
      "                  7\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"occupation\": {\n",
      "            \"column_name\": \"occupation\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.19182922339975303,\n",
      "            \"drift_detected\": true,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Adm-clerical\",\n",
      "                  \"Armed-Forces\",\n",
      "                  \"Craft-repair\",\n",
      "                  \"Exec-managerial\",\n",
      "                  \"Farming-fishing\",\n",
      "                  \"Handlers-cleaners\",\n",
      "                  \"Machine-op-inspct\",\n",
      "                  \"Other-service\",\n",
      "                  \"Priv-house-serv\",\n",
      "                  \"Prof-specialty\",\n",
      "                  \"Protective-serv\",\n",
      "                  \"Sales\",\n",
      "                  \"Tech-support\",\n",
      "                  \"Transport-moving\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4670,\n",
      "                  10,\n",
      "                  4501,\n",
      "                  4505,\n",
      "                  939,\n",
      "                  1422,\n",
      "                  2122,\n",
      "                  3366,\n",
      "                  129,\n",
      "                  3216,\n",
      "                  781,\n",
      "                  4351,\n",
      "                  1042,\n",
      "                  1726\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Adm-clerical\",\n",
      "                  \"Armed-Forces\",\n",
      "                  \"Craft-repair\",\n",
      "                  \"Exec-managerial\",\n",
      "                  \"Farming-fishing\",\n",
      "                  \"Handlers-cleaners\",\n",
      "                  \"Machine-op-inspct\",\n",
      "                  \"Other-service\",\n",
      "                  \"Priv-house-serv\",\n",
      "                  \"Prof-specialty\",\n",
      "                  \"Protective-serv\",\n",
      "                  \"Sales\",\n",
      "                  \"Tech-support\",\n",
      "                  \"Transport-moving\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  941,\n",
      "                  5,\n",
      "                  1611,\n",
      "                  1581,\n",
      "                  551,\n",
      "                  650,\n",
      "                  900,\n",
      "                  1557,\n",
      "                  113,\n",
      "                  2956,\n",
      "                  202,\n",
      "                  1153,\n",
      "                  404,\n",
      "                  629\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"race\": {\n",
      "            \"column_name\": \"race\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.003051106861330099,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Amer-Indian-Eskimo\",\n",
      "                  \"Asian-Pac-Islander\",\n",
      "                  \"Black\",\n",
      "                  \"Other\",\n",
      "                  \"White\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  329,\n",
      "                  1046,\n",
      "                  3362,\n",
      "                  240,\n",
      "                  29710\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Amer-Indian-Eskimo\",\n",
      "                  \"Asian-Pac-Islander\",\n",
      "                  \"Black\",\n",
      "                  \"Other\",\n",
      "                  \"White\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  141,\n",
      "                  473,\n",
      "                  1323,\n",
      "                  166,\n",
      "                  12052\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"relationship\": {\n",
      "            \"column_name\": \"relationship\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.007765049495800667,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Husband\",\n",
      "                  \"Not-in-family\",\n",
      "                  \"Other-relative\",\n",
      "                  \"Own-child\",\n",
      "                  \"Unmarried\",\n",
      "                  \"Wife\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  13682,\n",
      "                  9073,\n",
      "                  1038,\n",
      "                  5634,\n",
      "                  3604,\n",
      "                  1656\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Husband\",\n",
      "                  \"Not-in-family\",\n",
      "                  \"Other-relative\",\n",
      "                  \"Own-child\",\n",
      "                  \"Unmarried\",\n",
      "                  \"Wife\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  6034,\n",
      "                  3510,\n",
      "                  468,\n",
      "                  1947,\n",
      "                  1521,\n",
      "                  675\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"sex\": {\n",
      "            \"column_name\": \"sex\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.002874406423548237,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Female\",\n",
      "                  \"Male\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  11752,\n",
      "                  22935\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Female\",\n",
      "                  \"Male\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  4440,\n",
      "                  9715\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"workclass\": {\n",
      "            \"column_name\": \"workclass\",\n",
      "            \"column_type\": \"cat\",\n",
      "            \"stattest_name\": \"PSI\",\n",
      "            \"stattest_threshold\": 0.1,\n",
      "            \"drift_score\": 0.013185895855520359,\n",
      "            \"drift_detected\": false,\n",
      "            \"current\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Federal-gov\",\n",
      "                  \"Local-gov\",\n",
      "                  \"Never-worked\",\n",
      "                  \"Private\",\n",
      "                  \"Self-emp-inc\",\n",
      "                  \"Self-emp-not-inc\",\n",
      "                  \"State-gov\",\n",
      "                  \"Without-pay\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  1071,\n",
      "                  2050,\n",
      "                  4,\n",
      "                  24520,\n",
      "                  1176,\n",
      "                  2610,\n",
      "                  1336,\n",
      "                  17\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"reference\": {\n",
      "              \"small_distribution\": {\n",
      "                \"x\": [\n",
      "                  \"Federal-gov\",\n",
      "                  \"Local-gov\",\n",
      "                  \"Never-worked\",\n",
      "                  \"Private\",\n",
      "                  \"Self-emp-inc\",\n",
      "                  \"Self-emp-not-inc\",\n",
      "                  \"State-gov\",\n",
      "                  \"Without-pay\"\n",
      "                ],\n",
      "                \"y\": [\n",
      "                  361,\n",
      "                  1086,\n",
      "                  6,\n",
      "                  9386,\n",
      "                  519,\n",
      "                  1252,\n",
      "                  645,\n",
      "                  4\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"current_fi\": null,\n",
      "        \"reference_fi\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"timestamp\": \"2024-10-21 12:13:34.206277\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_data = '[{\"ID\":10,\"Name\":\"Pankaj\",\"Role\":\"CEO\"},' \\\n",
    "            '{\"ID\":20,\"Name\":\"David Lee\",\"Role\":\"Editor\"}]'\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.options import ColorOptions\n",
    "from evidently.report import Report\n",
    "\n",
    "from evidently.metrics import ColumnDriftMetric\n",
    "from evidently.metrics import DataDriftTable\n",
    "from evidently.metrics import DatasetDriftMetric\n",
    "from evidently.metrics import ColumnCategoryMetric\n",
    "from evidently.metrics import ColumnDistributionMetric\n",
    "from evidently.metrics import ColumnValuePlot\n",
    "from evidently.metrics import ColumnQuantileMetric\n",
    "from evidently.metrics import ColumnCorrelationsMetric\n",
    "from evidently.metrics import ColumnValueListMetric\n",
    "from evidently.metrics import ColumnValueRangeMetric\n",
    "\n",
    "#Dataset for Data Quality and Integrity\n",
    "adult_data = datasets.fetch_openml(name='adult', version=2, as_frame=True)\n",
    "adult = adult_data.frame\n",
    "print(\"\\n -----> \", adult.shape)\n",
    "\n",
    "\n",
    "adult_ref = adult[~adult.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "adult_cur = adult[adult.education.isin(['Some-college', 'HS-grad', 'Bachelors'])]\n",
    "\n",
    "#print(\"\\n =====> \", adult_ref)\n",
    "#print(\"\\n ******> \", adult_cur.shape)\n",
    "\n",
    "adult_cur.iloc[:2000, 3:5] = np.nan\n",
    "\n",
    "data_drift_dataset_report = Report(metrics=[\n",
    "    DataDriftTable(num_stattest='kl_div', cat_stattest='psi'),    \n",
    "])\n",
    "\n",
    "data_drift_dataset_report.run(reference_data=adult_ref, current_data=adult_cur)\n",
    "data_drift_dataset_report\n",
    "\n",
    "#report in a JSON format\n",
    "# data_drift_dataset_report.json()\n",
    "\n",
    "json_object = json.loads(data_drift_dataset_report.json())\n",
    "\n",
    "json_formatted_str = json.dumps(json_object, indent=2)\n",
    "\n",
    "print(json_formatted_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c181d55-082f-41ca-a57b-2d1c19d0cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 765\u001b[0m\n\u001b[0;32m    762\u001b[0m dataset_attr_5 \u001b[38;5;241m=\u001b[39m generate_dataset_with_attributes(dataset_transposed_ver, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_ver5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    763\u001b[0m dataset_attr_6 \u001b[38;5;241m=\u001b[39m generate_dataset_with_attributes(dataset_corrupted_ver, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_ver6\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 765\u001b[0m trained_model_ver_1 \u001b[38;5;241m=\u001b[39m train_model(trimmed_train_dataset_ver1)\n\u001b[0;32m    766\u001b[0m onyxmodel_ver_1 \u001b[38;5;241m=\u001b[39m generate_model_with_attributes(trained_model_ver_1, dataset_attr_1)\n\u001b[0;32m    768\u001b[0m trained_model_ver_2 \u001b[38;5;241m=\u001b[39m train_model(trimmed_train_dataset_ver2)\n",
      "Cell \u001b[1;32mIn[35], line 734\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    720\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m    721\u001b[0m         loss  \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m    722\u001b[0m         metrics  \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m#tf.keras.metrics.CategoricalAccuracy(),\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam())\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# checkpoint_path = \"training_1/cp.ckpt\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# checkpoint_dir = os.path.dirname(checkpoint_path)\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    732\u001b[0m \n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# Train the model with the new callback\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(dataset[train], train_labels[train],batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[0;32m    735\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(test_images[test], test_labels[test])) \u001b[38;5;66;03m#, callbacks=[cp_callback])  # Pass callback to training\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model metadata setting up \n",
    "# And splitting dataset for drift measures\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import DataDriftTable\n",
    "from evidently.metrics import DatasetDriftMetric\n",
    "from evidently.metrics import DatasetSummaryMetric\n",
    "from evidently.metrics import DatasetMissingValuesMetric\n",
    "#from evidently.metrics import DatasetCorrelationMetric\n",
    "# from data_drift_detector import DataDriftDetector\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# from scikit-image.io import imread, imshow\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Example metadata chromosome structure\n",
    "class MetadataChromosome:\n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "        self.fitness = 0.0\n",
    "\n",
    "    def calculate_fitness(self):\n",
    "        # Define a fitness function based on the metadata\n",
    "        # For simplicity, we'll sum the metadata values\n",
    "        self.fitness = sum(self.metadata.values()) \n",
    "\n",
    "    def mutate(self):\n",
    "        # Randomly mutate one of the metadata values\n",
    "        key = random.choice(list(self.metadata.keys()))\n",
    "        self.metadata[key] = random.uniform(0, 1)\n",
    "\n",
    "    def crossover(self, other):\n",
    "        # Perform crossover with another chromosome\n",
    "        child_metadata = {}\n",
    "        for key in self.metadata.keys():\n",
    "            if random.random() < 0.5:\n",
    "                child_metadata[key] = self.metadata[key]\n",
    "            else:\n",
    "                child_metadata[key] = other.metadata[key]\n",
    "        return MetadataChromosome(child_metadata)\n",
    "\n",
    "# Initialize a population of chromosomes\n",
    "def initialize_population(size, metadata_keys):\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        metadata = {key: random.uniform(0, 1) for key in metadata_keys}\n",
    "        chromosome = MetadataChromosome(metadata)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "# Select parents for crossover\n",
    "def select_parents(population):\n",
    "    population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    return population[:2]\n",
    "\n",
    "# Genetic Algorithm\n",
    "def genetic_algorithm(metadata_keys, generations=100, population_size=10):\n",
    "    population = initialize_population(population_size, metadata_keys)\n",
    "\n",
    "    for generation in range(generations):\n",
    "        # Calculate fitness for each chromosome\n",
    "        for chromosome in population:\n",
    "            chromosome.calculate_fitness()\n",
    "\n",
    "        # Select parents\n",
    "        parents = select_parents(population)\n",
    "\n",
    "        # Create next generation\n",
    "        new_population = []\n",
    "        for _ in range(population_size // 2):\n",
    "            parent1, parent2 = random.sample(parents, 2)\n",
    "            child1 = parent1.crossover(parent2)\n",
    "            child2 = parent2.crossover(parent1)\n",
    "            child1.mutate()\n",
    "            child2.mutate()\n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "        # Print the best fitness of the current generation\n",
    "        best_fitness = max(chromosome.fitness for chromosome in population)\n",
    "        print(f\"Generation {generation + 1}: Best Fitness = {best_fitness}\")\n",
    "\n",
    "    # Return the best chromosome\n",
    "    best_chromosome = max(population, key=lambda x: x.fitness)\n",
    "    return best_chromosome\n",
    "\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "        breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    " \n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    " \n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i])\n",
    "\n",
    "                                             for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        psi_values = psi(expected, actual, buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "\n",
    "# Trying a different PSI procedure\n",
    "def psi(reference, monitored, bins=None):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) between a reference dataset and a monitored dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    reference (numpy.array): The reference dataset, representing the baseline distribution.\n",
    "    monitored (numpy.array): The monitored dataset, representing the distribution to compare against the reference.\n",
    "    bins (int, optional): The number of bins to use for the histograms. If set to None, Doane's formula will be used to calculate the number of bins. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated PSI value. A higher value indicates greater divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    # Get the full dataset\n",
    "    full_dataset = np.concatenate((reference, monitored))\n",
    "\n",
    "    # If bins is not parametrized, use Doane's formula for calculating number of bins\n",
    "    if bins is None:\n",
    "        _, bin_edges = np.histogram(full_dataset, bins=\"doane\")\n",
    "    else:  # If number of bins is specified\n",
    "        bin_edges = np.linspace(min(min(reference), min(monitored)), max(max(reference), max(monitored)), bins + 1)\n",
    "\n",
    "    # Calculate the histogram for each dataset\n",
    "    reference_hist, _ = np.histogram(reference, bins=bin_edges)\n",
    "    monitored_hist, _ = np.histogram(monitored, bins=bin_edges)\n",
    "\n",
    "    # Convert histograms to proportions\n",
    "    reference_proportions = reference_hist / np.sum(reference_hist)\n",
    "    monitored_proportions = monitored_hist / np.sum(monitored_hist)\n",
    "\n",
    "    # Replace zeroes to avoid division by zero or log of zero errors\n",
    "    monitored_proportions = np.where(monitored_proportions == 0, 1e-6, monitored_proportions)\n",
    "    reference_proportions = np.where(reference_proportions == 0, 1e-6, reference_proportions)\n",
    "\n",
    "    # Calculate PSI\n",
    "    psi_values = (monitored_proportions - reference_proportions) * np.log(monitored_proportions / reference_proportions)\n",
    "    psi = np.sum(psi_values)\n",
    "\n",
    "    print(\"************* \", psi)\n",
    "\n",
    "    return psi\n",
    "\n",
    "## Calculate psi for features\n",
    "psi_list = []\n",
    "\n",
    "# top_feature_list=df_salary_high.columns\n",
    "'''\n",
    "for feature in range(len(train_images[0])): #top_feature_list:\n",
    "        # Assuming you have a validation and training set\n",
    "        #psi_t = calculate_psi( dataset_ver1[0][feature], train_images[0][feature])\n",
    "        # psi_t = psi( dataset_ver1[feature], train_images[feature])\n",
    "        psi_list.append(psi_t)      \n",
    "        print('Stability index for column ',feature,'is',psi_t)\n",
    "'''\n",
    "\n",
    "def dataset_ver_one (image):\n",
    "    return ndimage.prewitt(image, axis=0)\n",
    "    #return ds.filter(lambda x: x < 5)\n",
    "\n",
    "def dataset_ver_two (image):\n",
    "    return ndimage.prewitt(image, axis=1)\n",
    "    #return ds.filter(lambda x: x < 5)\n",
    "\n",
    "def dataset_ver_three (prewitt_h, prewitt_v):\n",
    "    magnitude = np.sqrt(prewitt_h ** 2 + prewitt_v ** 2)\n",
    "    magnitude *= 255 / np.max(magnitude)\n",
    "    return magnitude\n",
    "    # dimage.prewitt(ds[0], axis=1)\n",
    "    # return ds.filter(lambda x: x < 5)\n",
    "    \n",
    "def generate_dataset_from_mnist(train_images, train_labels):\n",
    "    new_dataset = train_images.apply(dataset_fn)\n",
    "    list(dataset.as_numpy_iterator())\n",
    "\n",
    "    \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# edges_prewitt_vertical = prewitt_v(train_images[0])\n",
    "dataset_ver1 = []\n",
    "dataset_ver2 = []\n",
    "dataset_ver3 = []\n",
    "dataset_ver4 = []\n",
    "dataset_transposed_ver = []\n",
    "dataset_corrupted_ver = []\n",
    "    \n",
    "\n",
    "def transpose_image(img):\n",
    "    kernel = np.zeros((28,28),np.uint8)\n",
    "    blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    return blackhat\n",
    "    \n",
    "    #imgT = img.T\n",
    "    # print(\"\\n Shape: \", imgT.shape)\n",
    "    #return imgT\n",
    "\n",
    "\n",
    "def corrupted_image(img):\n",
    "    \n",
    "    kernel = np.zeros((28,28),np.uint8)\n",
    "    tophat = cv2.morphologyEx(img, cv2. MORPH_TOPHAT, kernel) #\n",
    "\n",
    "    return tophat\n",
    "    \n",
    "\n",
    "def add_gaussian_noise(img):\n",
    "    gauss_noise=np.ones((28,28),dtype=np.uint8)\n",
    "    # We then use a random distribution to determine the pixel values \n",
    "    # of the noise (in this case with a mean of 128 and a sigma of 20)\n",
    "    cv2.randn(gauss_noise,18,2)\n",
    "    gauss_noise=(gauss_noise*10.5).astype(np.uint8)\n",
    "    gn_img=cv2.add(img,gauss_noise)\n",
    "    # print(\"\\n **************** \", gn_img)\n",
    "\n",
    "    return gn_img\n",
    "\n",
    "\n",
    "for t in range(len(train_images)):\n",
    "    prewitt_h = dataset_ver_one(train_images[t]) #, axis=0)\n",
    "    prewitt_v = dataset_ver_two(train_images[t]) #, axis=1)    \n",
    "    magnitude = dataset_ver_three(prewitt_h, prewitt_v)\n",
    "    gaussian = add_gaussian_noise(train_images[t])\n",
    "    transposedImg = transpose_image(train_images[t])\n",
    "    corrputedImg = corrupted_image(train_images[t])\n",
    "    \n",
    "    dataset_ver1.append(prewitt_h)\n",
    "    dataset_ver2.append(prewitt_v)\n",
    "    dataset_ver3.append(magnitude)\n",
    "    dataset_ver4.append(gaussian)\n",
    "    dataset_transposed_ver.append(transposedImg)\n",
    "    dataset_corrupted_ver.append(corrputedImg)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize = (8, 8))\n",
    "\n",
    "axes[0, 0].imshow(train_images[3000])\n",
    "# axes[0, 1].imshow(dataset_ver1[3000])\n",
    "# axes[0, 1].imshow(dataset_ver2[3000])\n",
    "axes[0, 1].imshow(dataset_corrupted_ver[3000])\n",
    "axes[1, 0].imshow(dataset_ver4[3000])\n",
    "axes[1, 1].imshow(dataset_transposed_ver[3000])\n",
    "##### plt.savefig(\"dataset_output\")\n",
    "\n",
    "titles = [\"original dataset\", \"dataset_ver2\", \"dataset_ver3\", \"dataset_ver4\", \"dataset_transposed\",\"dataset_corrupted\"]\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.set_title(titles[i])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def image_blur():\n",
    "    custom_transform = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.75, 1.25),\n",
    "                           ),\n",
    "        transforms.ToTensor(),\n",
    "     ])\n",
    "\n",
    "\n",
    "    # Note transforms.ToTensor() scales input images\n",
    "    # to 0-1 range\n",
    "    train_dataset = datasets.CIFAR10(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=custom_transform,\n",
    "                                 download=False)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    for images, labels in train_loader:  \n",
    "        images2 = images\n",
    "        break\n",
    "\n",
    "    return images2\n",
    "\n",
    "\n",
    "def image_crop():\n",
    "    custom_transform = transforms.Compose([\n",
    "        transforms.Resize((38, 38)),\n",
    "        transforms.RandomCrop((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Note transforms.ToTensor() scales input images\n",
    "    # to 0-1 range\n",
    "    train_dataset = datasets.MNIST(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=custom_transform,\n",
    "                                 download=False)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    for images, labels in train_loader:  \n",
    "        images2 = images\n",
    "        break\n",
    "\n",
    "    return images2\n",
    "\n",
    "\n",
    "def image_flip():\n",
    "    custom_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "    # Note transforms.ToTensor() scales input images\n",
    "    # to 0-1 range\n",
    "    train_dataset = datasets.CIFAR10(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=custom_transform,\n",
    "                                 download=False)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    for images, labels in train_loader:  \n",
    "        images2 = images\n",
    "        break\n",
    "\n",
    "     return images2\n",
    "\n",
    "\n",
    "def image_rotate():\n",
    "    \n",
    "    custom_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=90,\n",
    "                              resample=PIL.Image.BILINEAR),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "    # Note transforms.ToTensor() scales input images\n",
    "    # to 0-1 range\n",
    "    train_dataset = datasets.MNIST(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=custom_transform,\n",
    "                                 download=False)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    for images, labels in train_loader:  \n",
    "        images2 = images\n",
    "        break\n",
    "\n",
    "    return images2\n",
    "\n",
    "\n",
    "def show_transformed_images(images2):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(9, 3), sharey=True)\n",
    "    for i in range(5):\n",
    "        axs[i].imshow(np.transpose(images2[i], (1, 2, 0)))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def dataset_identifiers(titles):\n",
    "    dataset_idents = {}\n",
    "    \n",
    "    dataset_idents.update({\n",
    "                        titles[0]: dataset_ver1,\n",
    "                        titles[1]: dataset_ver2,\n",
    "                        titles[2]: dataset_ver3,\n",
    "                        titles[3]: dataset_ver4,\n",
    "                        titles[4]: dataset_transposed_ver,\n",
    "                        titles[1]: dataset_corrupted_ver,\n",
    "                      })\n",
    "\n",
    "    return dataset_idents\n",
    "    \n",
    "\n",
    "def get_report(reference_data, current_data):\n",
    "    data_drift_dataset_report = Report(metrics=[DatasetMissingValuesMetric(), ])\n",
    "\n",
    "    data_drift_dataset_report.run(reference_data=reference_data, current_data=current_data,  column_mapping=None) #\n",
    "    data_drift_dataset_report.save(\"current_dataset_report.json\")\n",
    "\n",
    "\n",
    "def print_metric():\n",
    "    # Load the JSON report\n",
    "    with open('current_dataset_report.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Accessing accuracy from the JSON report\n",
    "    num_missing_values = None\n",
    "    row_is_missing = False\n",
    "    col_is_missing = False\n",
    "    found_missing_entries = False\n",
    "    \n",
    "    metric_results = data['suite']['metric_results']\n",
    "    \n",
    "    for result in metric_results:                        \n",
    "        if 'current' in result:\n",
    "            tot_num_of_row = result['current'].get('number_of_rows')\n",
    "            tot_num_of_col = result['current'].get('number_of_columns')\n",
    "            \n",
    "            num_missing_values = result['current'].get('number_of_rows_with_missing_values') # .get('accuracy')\n",
    "            if num_missing_values > 0:\n",
    "                row_is_missing = True\n",
    "                perc_row = float(num_missing_values /tot_num_of_row)*100\n",
    "                print(\"\\n The following statistics about missing entries:: \", perc_row)\n",
    "                row_is_missing = True\n",
    "            else:\n",
    "                row_is_missing = False\n",
    "                #print(\"\\n No rows were found with missing values\")\n",
    "\n",
    "            col_num_missing_values = result['current'].get('number_of_columns_with_missing_values') # .get('accuracy')            \n",
    "            if col_num_missing_values > 0:\n",
    "                col_is_missing = True\n",
    "                perc_col = float(col_num_missing_values/tot_num_of_col)*100\n",
    "                #print(\"\\n The following statistics about missing entries:: \", perc_col)\n",
    "            else:\n",
    "                col_is_missing = False\n",
    "                #print(\"\\n No columns were found with missing values\")\n",
    "\n",
    "    if row_is_missing or col_is_missing:\n",
    "        found_missing_entries = True\n",
    "\n",
    "    return found_missing_entries\n",
    "    \n",
    "    \n",
    "def get_drift_in_dataset(base_df,current_df)->bool: \n",
    "    status = True\n",
    "    report={}\n",
    "    threshold=0.05\n",
    "    for column in base_df.columns:\n",
    "        d1 = base_df[column]\n",
    "        d2 = current_df[column]\n",
    "        is_same_dist = ks_2samp(d1,d2)\n",
    "\n",
    "        if threshold<=is_same_dist.pvalue:\n",
    "            is_found=False\n",
    "        else:\n",
    "            status = False\n",
    "            is_found=True\n",
    "    \n",
    "    # print(\"p_value: \",float(is_same_dist.pvalue),\"drift_status: \",is_found) \n",
    "    #print(\"p_value: %2.25f --- drift_status: %s\" %(is_same_dist.pvalue,is_found)) #\" \", float(is_same_dist.pvalue)\n",
    "    return is_found #report\n",
    "\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28)\n",
    "\n",
    "#dataset_corrupted_ver = dataset_corrupted_ver.reshape(-1, 28 * 28)\n",
    "\n",
    "#print(\"\\n ***************** \", train_images[0], train_images[0].shape)\n",
    "#print(\"\\n Difference: \", dataset_corrupted_ver[0], dataset_corrupted_ver[0].shape)\n",
    "\n",
    "def get_dataset_drift(dataset):\n",
    "    count = 0                    \n",
    "    for t in range(len(train_images)):\n",
    "        base_df =  pd.DataFrame(train_images[t]) # pd.DataFrame(t) #\n",
    "        current_df =  pd.DataFrame(dataset[t]) # pd.DataFrame(t) #\n",
    "        observed_drift = get_drift_in_dataset(base_df, current_df)  \n",
    "        get_report(base_df, current_df)\n",
    "        if observed_drift:\n",
    "            count = count + 1\n",
    "\n",
    "    return count/len(train_images)\n",
    "    \n",
    "#dataset_metrics(train_images, dataset_corrupted_ver)\n",
    "print_metric()\n",
    "# percent_drift_dataset = (get_dataset_drift()/len(train_images))*100\n",
    "\n",
    "# print(\"\\n Percentage Drift: \", percent_drift_dataset, \" -----Total images that had drift: \", count)\n",
    "# print(\"\\n ********** \", train_images.shape, len(dataset_ver1[0]))\n",
    "\n",
    "\n",
    "### - This is another attempt ################\n",
    "\n",
    "# To speed up these runs, use the first 1000 examples\n",
    "#train_labels = train_labels[:1000]\n",
    "#test_labels = test_labels[:1000]\n",
    "\n",
    "#train_images = train_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "#test_images = test_images[:1000].reshape(-1, 28 * 28) # / 255.0\n",
    "\n",
    "trimmed_train_dataset_ver1 = dataset_ver1[:1000]\n",
    "trimmed_train_dataset_ver2 = dataset_ver2[:1000]\n",
    "trimmed_train_dataset_ver3 = dataset_ver3[:1000]\n",
    "trimmed_train_dataset_ver4 = dataset_ver4[:1000]\n",
    "trimmed_train_dataset_transposed_ver = dataset_transposed_ver[:1000]\n",
    "trimmed_train_dataset_corrupted_ver = dataset_corrupted_ver[:1000]\n",
    "\n",
    "\n",
    "# meta_dataset = DatasetWithMeta(dataset_ver1, test_labels, )\n",
    "\n",
    "def generate_dataset_with_attributes(dataset, datasetID):\n",
    "    import datetime, time\n",
    "    ts = time.time()\n",
    "    dataset_timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    dataset_attr = {}\n",
    "    # datasetID = titles.get(dataset)\n",
    "    version = datasetID+\"_\"+dataset_timestamp\n",
    "    \n",
    "    empties_found = print_metric()    \n",
    "    publisher = \"DFKI\"\n",
    "    #checksum = get_dataset_checksum(dataset)\n",
    "    percent_drift_dataset = get_dataset_drift(dataset)\n",
    "    attr = [datasetID, dataset_timestamp, publisher, empties_found, percent_drift_dataset] # checksum\n",
    "    \n",
    "    dataset_attr.update({version:attr})\n",
    "    \n",
    "    return dataset_attr\n",
    "\n",
    "\n",
    "'''    \n",
    "    We use the gini index to measure the spasrity in the weights\n",
    "    Sparsity: if weight norm (\"average\") is low, the model is sparse. May or may not be beneficial.\n",
    "'''\n",
    "\n",
    "def get_weight_sparsity(model, w=None):\n",
    "    # The rest of the code requires numpy arrays.\n",
    "    input_layer, hidden_layer, output_layer = get_model_internals(model)\n",
    "    all_layer = [input_layer,hidden_layer,output_layer]\n",
    "    sparse_measure = 0.0\n",
    "    t = []\n",
    "\n",
    "    for layer in all_layers:\n",
    "        x = np.asarray(layer)\n",
    "        if w is not None:\n",
    "            w = np.asarray(w)\n",
    "            sorted_indices = np.argsort(x)\n",
    "            sorted_x = x[sorted_indices]\n",
    "            sorted_w = w[sorted_indices]\n",
    "            # Force float dtype to avoid overflows\n",
    "            cumw = np.cumsum(sorted_w, dtype=float)\n",
    "            cumxw = np.cumsum(sorted_x * sorted_w, dtype=float)\n",
    "            return (np.sum(cumxw[1:] * cumw[:-1] - cumxw[:-1] * cumw[1:]) / \n",
    "                (cumxw[-1] * cumw[-1]))\n",
    "        else:\n",
    "            sorted_x = np.sort(x)\n",
    "            n = len(x)\n",
    "            cumx = np.cumsum(sorted_x, dtype=float)\n",
    "            # The above formula, with all weights equal to 1 simplifies to:\n",
    "            #return (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "            t[layers] = (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "\n",
    "    return float(np.sum(t)/len(all_layers))\n",
    "    \n",
    "\n",
    "def get_dataset_checksum(dataset_file):\n",
    "    import hashlib\n",
    "    checksum = hashlib.md5(open(dataset_file,'rb').read()).hexdigest()\n",
    "\n",
    "    return checksum\n",
    "    \n",
    "    \n",
    "def get_model_weights_analysis(model):\n",
    "    '''\n",
    "        1.  get weight stability by avergaing over the weights across different layers\n",
    "            This will give some kind of variance, std-dev, decay rate parameter\n",
    "            the distribution of this weight decay is then an exponential distrobution\n",
    "            The rate parameter of this distribution is then the measure of the sparsity of the weights\n",
    "        2. Then we need another measure for the health of the weights\n",
    "        3. And another measure for the weight sparsity - 3 and 2 carry less weight than 1 in the fitness algorithm\n",
    "\n",
    "        This procedure returns these as coefficients \n",
    "    '''\n",
    "\n",
    "    num_trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "\n",
    "    nonzero_threshold = 60\n",
    "    health_status = False\n",
    "    total_parameters = 0\n",
    "    \n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(shape)\n",
    "        print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)\n",
    "\n",
    "    nonzero_parameters = np.sum([np.count_nonzero(var) for var in total_parameters])\n",
    "\n",
    "    percent_nonzeros = float(nonzero_parameters/total_parameters) * 100\n",
    "    \n",
    "    health_status = True if percent_nonzeros > nonzero_threshold else False\n",
    "\n",
    "    return health_status\n",
    "    \n",
    "\n",
    "def get_layers_in_NN(model):\n",
    "\n",
    "    conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "\n",
    "    return model.layers\n",
    "    \n",
    "\n",
    "def print_stats(nparray):\n",
    "    print(\"Shape: \", nparray.shape)\n",
    "    print(\"Mean: \", np.mean(nparray))\n",
    "    print(\"Standard Deviation: \", np.std(nparray))\n",
    "    print(\"Variance: \", np.var(nparray))\n",
    "    print(\"Min: \", np.min(nparray))\n",
    "    print(\"Max: \", np.max(nparray))\n",
    "\n",
    "\n",
    "def plot_histo(nparray, model_name, layer, param):\n",
    "    assert param in {'weights', 'biases'}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(np.asarray(nparray).flatten(), rwidth=0.9)\n",
    "    plt.title(f\"Plot of {model_name} {param} in {layer} layer\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "\n",
    "def summarize(nparray, model_name=None, layer=None, param=None):\n",
    "    print_stats(nparray)\n",
    "    plot_histo(nparray, model_name, layer, param)\n",
    "\n",
    "\n",
    "def get_weight_sums(conv_layers):\n",
    "    weight_sums = []\n",
    "    for conv_layer in conv_layers:\n",
    "        weights = conv_layer.get_weights()[0]\n",
    "        weight_sums.append(sum(sum(sum(sum(abs(weights / weights.size))))))\n",
    "    return weight_sums\n",
    "\n",
    "\n",
    "def plot_layer_mean_weight(weight_sums, model):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(range(len(weight_sums)), weight_sums)\n",
    "    plt.title(f\"Weight changing by layer in {model}\")\n",
    "    plt.ylabel(\"Mean of absolute value of weight\")\n",
    "    plt.xlabel(\"Convolutional layer number\")\n",
    "\n",
    "\n",
    "def get_decaying_rate(weight_sums):\n",
    "\n",
    "    decay_rate = 0.0\n",
    "    summed = 0.0\n",
    "    \n",
    "    for weigh in weight_sums:\n",
    "        summed = summed + float(1/weigh)\n",
    "\n",
    "    decay_rate = summed/len(weight_sums)\n",
    "\n",
    "    return decay_rate\n",
    "\n",
    "\n",
    "def get_model_internals(model):\n",
    "    \n",
    "    W = [], U = [], b = []\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        W.append(model.layers[layer].get_weights()[0])\n",
    "        U.append(model.layers[layer].get_weights()[1])\n",
    "        b.append(model.layers[layer].get_weights()[2])\n",
    "\n",
    "    return W, U, b\n",
    "\n",
    "\n",
    "def generate_model_with_attributes(model):\n",
    "    import tf2onnx\n",
    "    import onnx\n",
    "\n",
    "    input_signature = [tf.TensorSpec([3, 3], tf.float32, name='x')]\n",
    "    # Use from_function for tf functions\n",
    "    \n",
    "    onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=13)\n",
    "    # onnx.save(onnx_model, \"dst/path/model.onnx\")\n",
    "    model_owner = \"DFKI\"\n",
    "\n",
    "    weight_profile = {'health': get_model_weights_analysis(model), 'sparsity': get_weight_sparsity(model), 'stability': get_decaying_rate(weight_sums)}\n",
    "\n",
    "    dataset_profile = generate_dataset_with_attributes()\n",
    "\n",
    "    attr1 = onnx_model.metadata_props.add()\n",
    "    attr1.key = 'weight_stats'\n",
    "    attr1.value = json.dumps(weight_profile)\n",
    "\n",
    "    # we take the domain to be the class of the actual task at hand\n",
    "    attr2 = onnx_model.metadata_props.add()\n",
    "    attr2.key = 'domain'\n",
    "    attr2.value = json.dumps(\"ml.task.image-classification\")\n",
    "\n",
    "    attr3 = onnx_model.metadata_props.add()\n",
    "    attr3.key = 'model_version'\n",
    "    attr3.value = json.dumps(model_ver)\n",
    "\n",
    "    attr4 = onnx_model.metadata_props.add()\n",
    "    attr4.key = 'producer_name'\n",
    "    attr4.value = json.dumps(model_owner)\n",
    "\n",
    "    attr5 = onnx_model.metadata_props.add()\n",
    "    attr5.key = 'dataset_properties'\n",
    "    attr5.value = json.dumps(dataset_profile)\n",
    "\n",
    "    onnx.save(onnx_model.onnx, 'deeplabv3_landcover_4c.onnx')\n",
    "\n",
    "    return onnx_model\n",
    "\n",
    "    #print(\"doc_string={}\".format(model.doc_string))\n",
    "    #print(\"domain={}\".format(model.domain))\n",
    "    #print(\"ir_version={}\".format(model.ir_version))\n",
    "    #print(\"metadata_props={}\".format(model.metadata_props))\n",
    "    #print(\"model_version={}\".format(model.model_version))\n",
    "    #print(\"producer_name={}\".format(model.producer_name))\n",
    "\n",
    "    # model_attributes = {}\n",
    "\n",
    "\n",
    "'''\n",
    "    Now we try to train the models\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# import apache_beam as beam\n",
    "# import tensorflow_model_analysis as tfma\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(dataset):\n",
    "# Create a basic model instance\n",
    "    model = create_model()\n",
    "    # print(\"\\n MODEL => \", model)\n",
    "\n",
    "    for kfold, (train, test) in enumerate(KFold(n_splits=3, shuffle=True).split(dataset, train_labels[:1000])): #split(X, y)):\n",
    "        # clear the session \n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # calling the model and compile it \n",
    "        #seq_model = my_model()\n",
    "        model.compile(\n",
    "            loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics  = ['mae', 'acc', 'mape'], #tf.keras.metrics.CategoricalAccuracy(),\n",
    "            optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "    # checkpoint_path = \"training_1/cp.ckpt\"\n",
    "    # checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    # cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "    #                                             save_weights_only=True,\n",
    "    #                                             verbose=1)\n",
    "\n",
    "    # Train the model with the new callback\n",
    "    model.fit(dataset[train], train_labels[train],batch_size=128, \n",
    "              epochs=20, validation_data=(test_images[test][:1000], test_labels[test][:1000])) #, callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def persist_model_to_disk(model, model_name):\n",
    "    # Display the model's architecture\n",
    "    print(\"\\n ****************** Model Arch *************************** \\n\")\n",
    "    model.summary()\n",
    "    # model.save_weights(f'wg_{kfold}.h5')\n",
    "\n",
    "    filepath = \"/home/antillas/collabos/model_aggregation\"\n",
    "    # Save all The model's configuration (architecture), The model's weights, \n",
    "    # Saves a model as a .keras file - The model's optimizer's state (if any)\n",
    "\n",
    "    model.save(\"kera_model_one.keras\")\n",
    "\n",
    "    # Saves all layer weights to a .weights.h5 file.\n",
    "    model.save_weights(f'wg_{kfold}.h5',\n",
    "        filepath, overwrite=True\n",
    "    )\n",
    "\n",
    "# Now create the model with the respective dataset attributes\n",
    "dataset_attr_1 = generate_dataset_with_attributes(dataset_ver1, \"dataset_ver1\")\n",
    "dataset_attr_2 = generate_dataset_with_attributes(dataset_ver2, \"dataset_ver2\")\n",
    "dataset_attr_3 = generate_dataset_with_attributes(dataset_ver3, \"dataset_ver3\")\n",
    "dataset_attr_4 = generate_dataset_with_attributes(dataset_ver4, \"dataset_ver4\")\n",
    "dataset_attr_5 = generate_dataset_with_attributes(dataset_transposed_ver, \"dataset_ver5\")\n",
    "dataset_attr_6 = generate_dataset_with_attributes(dataset_corrupted_ver, \"dataset_ver6\")\n",
    "\n",
    "trained_model_ver_1 = train_model(trimmed_train_dataset_ver1)\n",
    "onyxmodel_ver_1 = generate_model_with_attributes(trained_model_ver_1, dataset_attr_1)\n",
    "\n",
    "trained_model_ver_2 = train_model(trimmed_train_dataset_ver2)\n",
    "onyxmodel_ver_2 = generate_model_with_attributes(trained_model_ver_2, dataset_attr_2)\n",
    "\n",
    "trained_model_ver_3 = train_model(trimmed_train_dataset_ver3)\n",
    "onyxmodel_ver_3 = generate_model_with_attributes(trained_model_ver_3, dataset_attr_3)\n",
    "\n",
    "trained_model_ver_4 = train_model(trimmed_train_dataset_ver4)\n",
    "onyxmodel_ver_4 = generate_model_with_attributes(trained_model_ver_4, dataset_attr_4)\n",
    "\n",
    "trained_model_ver_5 = train_model(trimmed_train_dataset_transposed_ver)\n",
    "onyxmodel_ver_5 = generate_model_with_attributes(trained_model_ver_5, dataset_attr_5)\n",
    "\n",
    "trained_model_ver_6 = train_model(trimmed_train_dataset_corrupted_ver)\n",
    "onyxmodel_ver_6 = generate_model_with_attributes(trained_model_ver_6, dataset_attr_6)\n",
    "\n",
    "#persist_model_to_disk(model, dataset_attr.get(\"dataset_ver1\"))\n",
    "\n",
    "# Step 3:\n",
    "\n",
    "# Step 4:\n",
    "\n",
    "# Step 5:\n",
    "# metadata_keys = get_model_metadata(onyxmodel) \n",
    "metadata_keys = np.concatenate(onyxmodel_ver_1.metadata_props, onyxmodel_ver_2.metadata_props, onyxmodel_ver_3.metadata_props, \n",
    "                              onyxmodel_ver_4.metadata_props, onyxmodel_ver_5.metadata_props, onyxmodel_ver_6.metadata_props)\n",
    "\n",
    "best_chromosome = genetic_algorithm(metadata_keys)\n",
    "print(\"Best Chromosome:\", best_chromosome.metadata)\n",
    "\n",
    "\n",
    "'''\n",
    "  FedAvg - Load pretrained models and do aggregations \n",
    "'''\n",
    "\n",
    "# conv_layers = get_layers_in_NN(model)\n",
    "# weight_sums = get_weight_sums(conv_layers)\n",
    "# decaying_rate = get_decaying_rate(weight_sums)\n",
    "# print(\"\\n Decaying rate: \", decaying_rate)\n",
    "\n",
    "# plot_layer_mean_weight(weight_sums, 'VGG-16')\n",
    "\n",
    "# What we want to accomplish\n",
    "# Next steps for the \n",
    "'''\n",
    "1: Use the metadata extractor here to retrieve any metadata about the pretrained models\n",
    "\n",
    "2: A component for the metadata schema validator\n",
    "\n",
    "3: Give weights to each model metadata -> Kind of a fitnesss functions\n",
    "\n",
    "4: Encode metadata as chromosomes\n",
    "\n",
    "5: Do generic algorithm for Model aggregation\n",
    "\n",
    "6: Do FedAvg aggregations\n",
    "\n",
    "7: Evaluate the model from FedAvg against the Genetic model(metrics like acc, mape, etc) given different runs under fitness functions adjustments\n",
    "'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
