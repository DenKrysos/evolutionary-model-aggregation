{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913f8cd1-6f36-44a5-b2a1-5ae7f99ce3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_402372/1133149414.py\u001b[0m in \u001b[0;36m<cell line: 313>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;31m# Run federated learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_learning_with_ga\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;31m#global_model = federated_learning()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_402372/1133149414.py\u001b[0m in \u001b[0;36mfederated_learning_with_ga\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Run genetic algorithm to find the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         best_chromosome = genetic_algorithm(metadata_keys=['model'], models=client_models, population=population, \n\u001b[0m\u001b[1;32m    223\u001b[0m                                             generations=10, population_size=NUM_CLIENTS)\n\u001b[1;32m    224\u001b[0m         \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_chromosome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_402372/1133149414.py\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(metadata_keys, models, population, generations, population_size)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Calculate fitness for each chromosome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchromosome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mchromosome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Select parents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_402372/1133149414.py\u001b[0m in \u001b[0;36mcalculate_fitness\u001b[0;34m(self, models)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# from metadata import MetadataChromosome, initialize_population, select_parents, genetic_algorithm\n",
    "\n",
    "class MetadataChromosome:\n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "        self.fitness = 0.0\n",
    "\n",
    "    def calculate_fitness(self, models):\n",
    "        \"\"\"\n",
    "        Evaluates different pretrained MobileNetV3 weight spaces based on accuracy, sparsity, stability, and weight health.\n",
    "    \n",
    "        Args:\n",
    "            models (list): List of models with different weights.\n",
    "            validation_loader (DataLoader): Validation dataset.\n",
    "            alpha (float): Weight for accuracy.\n",
    "            beta (float): Weight for sparsity.\n",
    "            gamma (float): Weight for stability and weight health.\n",
    "\n",
    "        Returns:\n",
    "            best_model (torch.nn.Module): Model with the best weight space.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "        best_score = float('-inf')\n",
    "        best_model = None\n",
    "\n",
    "        for model in models:\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            sparsity = 0\n",
    "            num_params = 0\n",
    "            stability_scores = []\n",
    "            weight_health_scores = []\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for images, labels in validation_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    # Run multiple forward passes for stability check\n",
    "                    outputs_list = []\n",
    "                    for _ in range(3):  # Three forward passes\n",
    "                        outputs = model(images)\n",
    "                        outputs_list.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "                    # Compute stability as variance across multiple predictions\n",
    "                    outputs_array = np.stack(outputs_list, axis=0)\n",
    "                    stability_score = -np.mean(np.var(outputs_array, axis=0))  # Lower variance is better\n",
    "                \n",
    "                    stability_scores.append(stability_score)\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "        \n",
    "            # Calculate accuracy\n",
    "            accuracy = correct / total\n",
    "\n",
    "            # Compute sparsity (percentage of zero weights)\n",
    "            for param in model.parameters():\n",
    "                num_params += param.numel()\n",
    "                sparsity += (param == 0).sum().item()\n",
    "        \n",
    "            sparsity_ratio = sparsity / num_params\n",
    "        \n",
    "            # Compute weight health (variance of weights should not be too low/high)\n",
    "            for param in model.parameters():\n",
    "                weight_std = torch.std(param).item()\n",
    "                weight_mean = torch.mean(param).item()\n",
    "                weight_health_score = -abs(weight_std - 1.0) - abs(weight_mean)  # Ideally, std close to 1 and mean close to 0\n",
    "                weight_health_scores.append(weight_health_score)\n",
    "        \n",
    "            avg_stability = np.mean(stability_scores)\n",
    "            avg_weight_health = np.mean(weight_health_scores)\n",
    "\n",
    "            # Define the fitness score (combination of accuracy, sparsity, stability, and weight health)\n",
    "            fitness_score = (\n",
    "                alpha * accuracy - beta * sparsity_ratio + gamma * (avg_stability + avg_weight_health)\n",
    "            )\n",
    "        \n",
    "            # Select the best model based on fitness score\n",
    "            if fitness_score > best_score:\n",
    "                best_score = fitness_score\n",
    "                best_model = model\n",
    "\n",
    "        return best_model\n",
    "    \n",
    "\n",
    "    def mutate(self):\n",
    "        # Randomly mutate one of the metadata values\n",
    "        key = random.choice(list(self.metadata.keys()))\n",
    "        self.metadata[key] = random.uniform(0, 1)\n",
    "\n",
    "    def crossover(self, other):\n",
    "        # Perform crossover with another chromosome\n",
    "        child_metadata = {}\n",
    "        for key in self.metadata.keys():\n",
    "            if random.random() < 0.5:\n",
    "                child_metadata[key] = self.metadata[key]\n",
    "            else:\n",
    "                child_metadata[key] = other.metadata[key]\n",
    "        return MetadataChromosome(child_metadata)\n",
    "\n",
    "\n",
    "# Initialize a population of chromosomes\n",
    "def initialize_model_population(models):\n",
    "    population = []\n",
    "    for model in models:\n",
    "        metadata = {'model': model}\n",
    "        chromosome = MetadataChromosome(metadata)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "#def initialize_population(size, metadata_keys):\n",
    "#    population = []\n",
    "#    for _ in range(size):\n",
    "#        metadata = {key: random.uniform(0, 1) for key in metadata_keys}\n",
    "#        chromosome = MetadataChromosome(metadata)\n",
    "#        population.append(chromosome)\n",
    "#    return population\n",
    "\n",
    "# Select parents for crossover\n",
    "def select_parents(population):\n",
    "    population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    return population[:2]\n",
    "\n",
    "\n",
    "# Genetic Algorithm\n",
    "def genetic_algorithm(metadata_keys, models, population, generations=100, population_size=10):\n",
    "    # population = initialize_population(population_size, metadata_keys)\n",
    "\n",
    "    for generation in range(generations):\n",
    "        # Calculate fitness for each chromosome\n",
    "        for chromosome in population:\n",
    "            chromosome.calculate_fitness(models)\n",
    "\n",
    "        # Select parents\n",
    "        parents = select_parents(population)\n",
    "\n",
    "        # Create next generation\n",
    "        new_population = []\n",
    "        for _ in range(population_size // 2):\n",
    "            parent1, parent2 = random.sample(parents, 2)\n",
    "            child1 = parent1.crossover(parent2)\n",
    "            child2 = parent2.crossover(parent1)\n",
    "            child1.mutate()\n",
    "            child2.mutate()\n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "        # Print the best fitness of the current generation\n",
    "        best_fitness = max(chromosome.fitness for chromosome in population)\n",
    "        print(f\"Generation {generation + 1}: Best Fitness = {best_fitness}\")\n",
    "\n",
    "    # Return the best chromosome\n",
    "    best_chromosome = max(population, key=lambda x: x.fitness)\n",
    "    return best_chromosome\n",
    "\n",
    "\n",
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 5  # Number of clients\n",
    "ROUNDS = 10  # Number of training rounds\n",
    "EPOCHS_PER_CLIENT = 2  # Local training epochs per client\n",
    "AGGREGATION_METHOD = \"FedAvg\"  # Federated averaging\n",
    "\n",
    "\n",
    "def federated_learning_with_ga():\n",
    "    # Define synthetic data\n",
    "    num_samples = 1000\n",
    "    num_classes = 10\n",
    "    image_size = (3, 224, 224)\n",
    "\n",
    "    # Generate random images and labels\n",
    "    images = torch.randn(num_samples, *image_size)\n",
    "    labels = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "    # Define preprocessing steps\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations to synthetic data\n",
    "    images = torch.stack([transform(image) for image in images])\n",
    "\n",
    "    # Create TensorDataset and DataLoader\n",
    "    synthetic_dataset = TensorDataset(images, labels)\n",
    "    train_loader = DataLoader(synthetic_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    \n",
    "    global_model = load_mobilenetv3()\n",
    "    clients = [load_mobilenetv3() for _ in range(NUM_CLIENTS)]\n",
    "    \n",
    "    # Update train_loaders\n",
    "    train_loaders = [train_loader for _ in range(NUM_CLIENTS)]  \n",
    "\n",
    "    for round in range(ROUNDS):\n",
    "        print(f\"Round {round+1}/{ROUNDS}\")\n",
    "        client_models = []\n",
    "\n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            client_model = copy.deepcopy(global_model)\n",
    "            updated_weights = train_client(client_model, train_loaders[client_id])\n",
    "            client_models.append(updated_weights)\n",
    "\n",
    "        # Initialize population with client models\n",
    "        population = initialize_model_population(client_models)\n",
    "\n",
    "        # Run genetic algorithm to find the best model\n",
    "        best_chromosome = genetic_algorithm(metadata_keys=['model'], models=client_models, population=population, \n",
    "                                            generations=10, population_size=NUM_CLIENTS)\n",
    "        global_model = best_chromosome.metadata['model']\n",
    "        print(\"Global model updated using Genetic Algorithm.\")\n",
    "\n",
    "        # Validation step\n",
    "        global_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = global_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Load Pretrained MobileNetV3 Model\n",
    "def load_mobilenetv3():\n",
    "    model = models.mobilenet_v3_small(pretrained=True)\n",
    "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, 10)  # Example: 10 classes\n",
    "    return model\n",
    "\n",
    "\n",
    "# Simulated Client Training\n",
    "def train_client(model, train_loader, epochs=EPOCHS_PER_CLIENT, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model.state_dict()\n",
    "\n",
    "\n",
    "# Federated Averaging (FedAvg)\n",
    "def federated_averaging(global_model, client_models):\n",
    "    new_state_dict = copy.deepcopy(global_model.state_dict())\n",
    "    for key in new_state_dict.keys():\n",
    "        new_state_dict[key] = torch.stack([client_models[i][key] for i in range(NUM_CLIENTS)], dim=0).mean(dim=0)\n",
    "    global_model.load_state_dict(new_state_dict)\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Federated Learning Simulation\n",
    "def federated_learning():\n",
    "    global_model = load_mobilenetv3()\n",
    "    clients = [load_mobilenetv3() for _ in range(NUM_CLIENTS)]\n",
    "    # # Replace with actual DataLoaders [None]\n",
    "    train_loaders =  DataLoader(dataset=train_dataset, batch_size=1000, num_workers=1, shuffle=True) * NUM_CLIENTS  \n",
    "\n",
    "    # Load dataset\n",
    "    train_dataset = datasets.ImageFolder(root='train_data_path/', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    for round in range(ROUNDS):\n",
    "        print(f\"Round {round+1}/{ROUNDS}\")\n",
    "        client_models = []\n",
    "        \n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            client_model = copy.deepcopy(global_model)\n",
    "            updated_weights = train_client(client_model, train_loaders[client_id])\n",
    "            client_models.append(updated_weights)\n",
    "        \n",
    "        global_model = federated_averaging(global_model, client_models)\n",
    "        print(\"Global model updated.\")\n",
    "    \n",
    "    return global_model\n",
    "\n",
    "# Run federated learning\n",
    "global_model = federated_learning_with_ga()\n",
    "\n",
    "#global_model = federated_learning()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304372ba-690b-4ba1-8759-bfe6c711dc83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
